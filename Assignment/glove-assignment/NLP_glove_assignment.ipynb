{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Submitted by:** \n",
        "          \n",
        "          Name: Ayush Koirala\n",
        "          id : st122802\n",
        "\n",
        "**Assignment on Glove **\n",
        "\n",
        "Constraint: Only use our code (not other code....)\n",
        "\n",
        "1. I guess you already try a bigger corpus\n",
        "2. I guess you already try window size 2\n",
        "3. I guess you already have skipgram, skipgram(neg), cbow, glove\n",
        "\n",
        "Do this:\n",
        "1. Compare them based on syntactic accuracy and semantic accuracy, similar to how is done in https://nlp.stanford.edu/pubs/glove.pdf (see Table 2) - NO NEED to try 1000 or 300 embed size.....I just want you to learn how to do experiment.....\n",
        "2. Try to find a correlation with just ONE similarity dataset (which humans judge how similar is two words.....)\n",
        "\n",
        "Point criteria:\n",
        "0:  Not done\n",
        "1: ok\n",
        "2: with comments / explanation / figures.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fU-YTqj4dMqp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Libraries**"
      ],
      "metadata": {
        "id": "Sf4p7uR_eEc4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iWJsrHp2SF4t"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ETL**"
      ],
      "metadata": {
        "id": "yoCXdK78eMaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk \n",
        "from nltk.corpus import brown\n",
        "nltk.download('brown')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTq9VskQSJ8_",
        "outputId": "42f871db-1e88-48bd-807b-7358b387e1f2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = brown.sents()[:1000]\n",
        "#Transforming to lower case\n",
        "corpus = [[word.lower() for word in sent] for sent in corpus] # Cool list comprehension trick!\n",
        "print(corpus[0:5])"
      ],
      "metadata": {
        "id": "HfGHKOS6S3Ly",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12963ce0-fa39-4387-eb18-3117159a412c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['the', 'fulton', 'county', 'grand', 'jury', 'said', 'friday', 'an', 'investigation', 'of', \"atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['the', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'city', 'executive', 'committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'city', 'of', 'atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ['the', 'september-october', 'term', 'jury', 'had', 'been', 'charged', 'by', 'fulton', 'superior', 'court', 'judge', 'durwood', 'pye', 'to', 'investigate', 'reports', 'of', 'possible', '``', 'irregularities', \"''\", 'in', 'the', 'hard-fought', 'primary', 'which', 'was', 'won', 'by', 'mayor-nominate', 'ivan', 'allen', 'jr.', '.'], ['``', 'only', 'a', 'relative', 'handful', 'of', 'such', 'reports', 'was', 'received', \"''\", ',', 'the', 'jury', 'said', ',', '``', 'considering', 'the', 'widespread', 'interest', 'in', 'the', 'election', ',', 'the', 'number', 'of', 'voters', 'and', 'the', 'size', 'of', 'this', 'city', \"''\", '.'], ['the', 'jury', 'said', 'it', 'did', 'find', 'that', 'many', 'of', \"georgia's\", 'registration', 'and', 'election', 'laws', '``', 'are', 'outmoded', 'or', 'inadequate', 'and', 'often', 'ambiguous', \"''\", '.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(corpus))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbwPt8rAeyII",
        "outputId": "6c4e5c30-7c30-4565-8d72-ca6e08574ba7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Doing flatten and Get word sequences and unique words**"
      ],
      "metadata": {
        "id": "24IjmIk4e7Fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Doing flatten and Get word sequences and unique words\n",
        "flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "vocab = list(set(flatten(corpus)))\n",
        "vocab[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SXA4kPhSQ_-",
        "outputId": "00e57710-032e-4c10-b8bb-73025aa557e3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['caldwell', 'list', 'after', 'tea', 'twelve']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AptY9PJ_Tv6u",
        "outputId": "c98b5874-b33a-46b1-c696-12c3289b2c2b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4272"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Numericalize**"
      ],
      "metadata": {
        "id": "EcDoWnate9bw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "word2index = {w: i for i, w in enumerate(vocab)}\n",
        "index2word = {v:k for k, v in word2index.items()}\n",
        "\n",
        "out = dict(itertools.islice(word2index.items(), 5))\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OJK6q5KUNMz",
        "outputId": "0ca3808f-52f5-4239-e446-07936fe9250e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'caldwell': 0, 'list': 1, 'after': 2, 'tea': 3, 'twelve': 4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab.append('<UNK>')\n",
        "word2index['<UNK>'] = 0"
      ],
      "metadata": {
        "id": "RMU7d_HrUWUe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Glove Method**"
      ],
      "metadata": {
        "id": "dsCxwVW1f8ii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#2. Build Co-occurence Matrix X and displaying only first 5\n",
        "from collections import Counter\n",
        "\n",
        "X_i = Counter(flatten(corpus)) # X_i\n",
        "out = dict(itertools.islice(X_i.items(), 5))\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtgmYi46U8z4",
        "outputId": "4eee8afc-079d-4ba5-e40d-62820bda6428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'the': 1569, 'fulton': 14, 'county': 35, 'grand': 7, 'jury': 23}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#modifing previous assignment random batch\n",
        "def random_batch_skipgram(corpus,window_size=1):\n",
        "    skip_grams = []\n",
        "    for sent in corpus:\n",
        "        for i in range(1, len(sent) - 1):  # we should start  from 1 because 0 has no context\n",
        "            target = sent[i]\n",
        "            context = []\n",
        "            for j in range(window_size):\n",
        "                if i - (j + 1) >= 0:  ## Checking  if anything fall outside of range from the left of list\n",
        "                     context.append(sent[i - (j + 1)])\n",
        "                if i + (j + 1) < len(sent): \n",
        "                     context.append(sent[i + (j + 1)])\n",
        "            for w in context:\n",
        "                skip_grams.append((target,w))\n",
        "    return skip_grams"
      ],
      "metadata": {
        "id": "0c_5ZhjbVWRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Find co-occurance in skip_grams with window of 2**"
      ],
      "metadata": {
        "id": "J1xefCoSjiVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_ik_skipgram = Counter(random_batch_skipgram(corpus,window_size=2))\n",
        "\n",
        "out = dict(itertools.islice(X_ik_skipgram.items(), 5))\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcdo5XUIW7DB",
        "outputId": "c50d9bf6-0963-471b-cba8-da4aca0d9375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{('fulton', 'the'): 7, ('fulton', 'county'): 6, ('fulton', 'grand'): 1, ('county', 'fulton'): 6, ('county', 'grand'): 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Weight function**"
      ],
      "metadata": {
        "id": "IofKlBaGplL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#simply a normalized function...don't worry too much\n",
        "def weighting(w_i, w_j, X_ik):\n",
        "        \n",
        "    #check whether the co-occurrences exist between these two words\n",
        "    try:\n",
        "        x_ij = X_ik[(w_i, w_j)]\n",
        "    except:\n",
        "        x_ij = 1  #if does not exist, set it to 1\n",
        "                \n",
        "    x_max = 100 #100 # fixed in paper  #cannot exceed 100 counts\n",
        "    alpha = 0.75\n",
        "    \n",
        "    #if co-occurrence does not exceed 100, scale it based on some alpha\n",
        "    if x_ij < x_max:\n",
        "        result = (x_ij/x_max)**alpha  #scale it\n",
        "    else:\n",
        "        result = 1  #if is greater than max, set it to 1 maximum\n",
        "    \n",
        "    return result"
      ],
      "metadata": {
        "id": "HF1IxQhJXoBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from itertools import combinations_with_replacement\n",
        "from itertools import combinations_with_replacement\n",
        "from tqdm import tqdm\n",
        "\n",
        "X_ik = {}  #for keeping the co-occurences\n",
        "weighting_dic = {} #scaling the percentage of sampling\n",
        "\n",
        "for bigram in tqdm(combinations_with_replacement(vocab, 2)):\n",
        "    if X_ik_skipgram.get(bigram) is not None:  #matches \n",
        "        co_occer = X_ik_skipgram[bigram]  #get the count from what we already counted\n",
        "        X_ik[bigram] = co_occer + 1 # + 1 for stability issue\n",
        "        X_ik[(bigram[1],bigram[0])] = co_occer+1   #count also for the opposite\n",
        "    else:\n",
        "        pass\n",
        "        \n",
        "    weighting_dic[bigram] = weighting(bigram[0], bigram[1], X_ik)\n",
        "    weighting_dic[(bigram[1], bigram[0])] = weighting(bigram[1], bigram[0], X_ik)\n",
        "\n",
        "print(f\"{X_ik=}\")\n",
        "print(f\"{weighting_dic=}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I97fp6RzXupq",
        "outputId": "ae8f1eb8-ccc3-4233-866f-ddd146c7974a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "9131401it [00:28, 321349.78it/s]\n",
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def random_batch(batch_size, word_sequence, skip_grams, X_ik, weighting_dic):\n",
        "    \n",
        "    #convert to id since our skip_grams is word, not yet id\n",
        "    skip_grams_id = [(word2index[skip_gram[0]], word2index[skip_gram[1]]) for skip_gram in skip_grams]\n",
        "    \n",
        "    random_inputs = []\n",
        "    random_labels = []\n",
        "    random_coocs  = []\n",
        "    random_weightings = []\n",
        "    random_index = np.random.choice(range(len(skip_grams_id)), batch_size, replace=False) #randomly pick without replacement\n",
        "        \n",
        "    for i in random_index:\n",
        "        random_inputs.append([skip_grams_id[i][0]])  # target, e.g., 2\n",
        "        random_labels.append([skip_grams_id[i][1]])  # context word, e.g., 3\n",
        "        \n",
        "        #get cooc\n",
        "        pair = skip_grams[i]\n",
        "        try:\n",
        "            cooc = X_ik[pair]\n",
        "        except:\n",
        "            cooc = 1\n",
        "        random_coocs.append([math.log(cooc)])\n",
        "        \n",
        "        #get weighting\n",
        "        weighting = weighting_dic[pair]\n",
        "        random_weightings.append([weighting])\n",
        "                    \n",
        "    return np.array(random_inputs), np.array(random_labels), np.array(random_coocs), np.array(random_weightings)"
      ],
      "metadata": {
        "id": "-N87EfKjX8ho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testing the method\n",
        "batch_size = 2 # mini-batch size\n",
        "skip_grams = random_batch_skipgram(corpus,window_size=2)\n",
        "input_batch, target_batch, cooc_batch, weighting_batch = random_batch(batch_size, corpus, skip_grams, X_ik, weighting_dic)\n",
        "\n",
        "print(\"Input: \", input_batch)\n",
        "print(\"Target: \", target_batch)\n",
        "print(\"Cooc: \", cooc_batch)\n",
        "print(\"Weighting: \", weighting_batch)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1PgfyVwZ86b",
        "outputId": "9589519a-efb3-4aed-bb8f-bfa0744a3c46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:  [[1543]\n",
            " [3056]]\n",
            "Target:  [[1079]\n",
            " [4058]]\n",
            "Cooc:  [[1.09861229]\n",
            " [0.69314718]]\n",
            "Weighting:  [[0.07208434]\n",
            " [0.05318296]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GloVe(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size,embed_size):\n",
        "        super(GloVe,self).__init__()\n",
        "        self.embedding_v = nn.Embedding(vocab_size, embed_size) # center embedding\n",
        "        self.embedding_u = nn.Embedding(vocab_size, embed_size) # out embedding\n",
        "        \n",
        "        self.v_bias = nn.Embedding(vocab_size, 1)\n",
        "        self.u_bias = nn.Embedding(vocab_size, 1)\n",
        "        \n",
        "    def forward(self, center_words, target_words, coocs, weighting):\n",
        "        center_embeds = self.embedding_v(center_words) # [batch_size, 1, emb_size]\n",
        "        target_embeds = self.embedding_u(target_words) # [batch_size, 1, emb_size]\n",
        "        \n",
        "        center_bias = self.v_bias(center_words).squeeze(1)\n",
        "        target_bias = self.u_bias(target_words).squeeze(1)\n",
        "        \n",
        "        inner_product = target_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2)\n",
        "        #[batch_size, 1, emb_size] @ [batch_size, emb_size, 1] = [batch_size, 1, 1] = [batch_size, 1]\n",
        "        \n",
        "        #note that coocs already got log\n",
        "        loss = weighting*torch.pow(inner_product +center_bias + target_bias - coocs, 2)\n",
        "        \n",
        "        return torch.sum(loss)"
      ],
      "metadata": {
        "id": "yVD_Gpy3Z_cF"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Glove Training**"
      ],
      "metadata": {
        "id": "Ha4jqnRstNSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Trying to use Colab\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5np6gz6tSKc",
        "outputId": "28d4c47e-0b4b-4bb2-d339-fdd3cd1de8e1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "voc_size = len(vocab)\n",
        "batch_size     = 10 # mini-batch size\n",
        "embedding_size = 100 #so we can later plot\n",
        "model          = GloVe(voc_size, embedding_size)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "A8mskB2Ct6tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "fNUrZa-IuNsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Training\n",
        "num_epochs = 5000\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    start = time.time()\n",
        "    \n",
        "    input_batch, target_batch, cooc_batch, weighting_batch = random_batch(batch_size, corpus, skip_grams, X_ik, weighting_dic)\n",
        "    input_batch  = torch.LongTensor(input_batch).to(device)          #[batch_size, 1]\n",
        "    target_batch = torch.LongTensor(target_batch).to(device)          #[batch_size, 1]\n",
        "    cooc_batch   = torch.FloatTensor(cooc_batch).to(device)           #[batch_size, 1]\n",
        "    weighting_batch = torch.FloatTensor(weighting_batch).to(device)   #[batch_size, 1]\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss = model(input_batch, target_batch, cooc_batch, weighting_batch)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    end = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start, end)\n",
        "\n",
        "    if (epoch + 1) % 1000 == 0:\n",
        "        print(f\"Epoch: {epoch + 1} | cost: {loss:.6f} | time: {epoch_mins}m {epoch_secs}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOferOn7aYis",
        "outputId": "3c47785c-c5fe-4dc8-d149-8b91c0c9ef96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1000 | cost: 115.496872 | time: 0m 0s\n",
            "Epoch: 2000 | cost: 98.368538 | time: 0m 0s\n",
            "Epoch: 3000 | cost: 80.760368 | time: 0m 0s\n",
            "Epoch: 4000 | cost: 24.985233 | time: 0m 0s\n",
            "Epoch: 5000 | cost: 24.683460 | time: 0m 0s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "path = '/content/Glove_5000.pth'\n",
        "torch.save(model.state_dict(), path)"
      ],
      "metadata": {
        "id": "UKdAJuEdaZAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now Trying for SkipGram**\n",
        "\n",
        "Taking everything from 1st assigment"
      ],
      "metadata": {
        "id": "Lf4faztJvii7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_batch(batch_size, word_sequence, window_size=1):\n",
        "    skip_grams = []\n",
        "    for sent in corpus:\n",
        "        for i in range(1, len(sent) - 1):\n",
        "            target = word2index[sent[i]]\n",
        "            context = []\n",
        "            for j in range(window_size):\n",
        "                if i - (j + 1) >= 0: \n",
        "                    context.append(word2index[sent[i - (j + 1)]])\n",
        "                \n",
        "                if i + (j + 1) < len(sent): \n",
        "                    context.append(word2index[sent[i + (j + 1)]])\n",
        "            for w in context:\n",
        "                skip_grams.append([target, w])\n",
        "    \n",
        "    random_inputs = []\n",
        "    random_labels = []\n",
        "    random_index = np.random.choice(range(len(skip_grams)), batch_size, replace=False) \n",
        "    for i in random_index:\n",
        "        random_inputs.append([skip_grams[i][0]])  \n",
        "        random_labels.append([skip_grams[i][1]])  \n",
        "            \n",
        "    return np.array(random_inputs), np.array(random_labels)"
      ],
      "metadata": {
        "id": "8a-6LyXlvh66"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testing\n",
        "batch_size =2 \n",
        "window_size = 2\n",
        "\n",
        "input_batch, target_batch = random_batch(batch_size, corpus, window_size)\n",
        "\n",
        "print(\"Input: \", input_batch)\n",
        "print(\"Target: \", target_batch)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOA7pXSgvh_h",
        "outputId": "8c7e3e92-6400-47f2-ad88-7a528712df86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:  [[2203]\n",
            " [1079]]\n",
            "Target:  [[4097]\n",
            " [4020]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Skipgram(nn.Module):\n",
        "    \n",
        "    def __init__(self, voc_size, emb_size):\n",
        "        super(Skipgram, self).__init__()\n",
        "        self.embedding_center_word  = nn.Embedding(voc_size, emb_size)  #is a lookup table mapping all ids in voc_size, into some vector of size emb_size\n",
        "        self.embedding_outside_word = nn.Embedding(voc_size, emb_size)\n",
        "    \n",
        "    def forward(self, center_word, outside_word, all_vocabs):\n",
        "        #center_word, outside_word: (batch_size, 1)\n",
        "        #all_vocabs: (batch_size, voc_size)\n",
        "        \n",
        "        #convert them into embedding\n",
        "        center_word_embed  = self.embedding_center_word(center_word)     #(batch_size, 1, emb_size)\n",
        "        outside_word_embed = self.embedding_outside_word(outside_word)   #(batch_size, 1, emb_size)\n",
        "        all_vocabs_embed   = self.embedding_outside_word(all_vocabs)     #(batch_size, voc_size, emb_size)\n",
        "        \n",
        "        #bmm is basically @ or .dot , but across batches (i.e., ignore the batch dimension)\n",
        "        top_term = outside_word_embed.bmm(center_word_embed.transpose(1, 2)).squeeze(2)\n",
        "        #(batch_size, 1, emb_size) @ (batch_size, emb_size, 1) = (batch_size, 1, 1) ===> (batch_size, 1)\n",
        "        \n",
        "        top_term_exp = torch.exp(top_term)  #exp(uo vc)\n",
        "        #(batch_size, 1)\n",
        "        \n",
        "        lower_term = all_vocabs_embed.bmm(center_word_embed.transpose(1, 2)).squeeze(2)\n",
        "         #(batch_size, voc_size, emb_size) @ (batch_size, emb_size, 1) = (batch_size, voc_size, 1) = (batch_size, voc_size)\n",
        "         \n",
        "        lower_term_sum = torch.sum(torch.exp(lower_term), 1) #sum exp(uw vc)\n",
        "        #(batch_size, 1)\n",
        "        \n",
        "        loss_fn = -torch.mean(torch.log(top_term_exp / lower_term_sum))\n",
        "        #(batch_size, 1) / (batch_size, 1) ==mean==> scalar\n",
        "        \n",
        "        return loss_fn"
      ],
      "metadata": {
        "id": "ivhrR5Uda65G"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "voc_size = len(vocab)\n",
        "voc_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JydLY5qBwoiy",
        "outputId": "a4cd40b1-7b2c-48b7-8790-bf8cfca9421f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4273"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 10\n",
        "\n",
        "def prepare_sequence(seq, word2index):\n",
        "    #map(function, list of something)\n",
        "    #map will look at each of element in this list, and apply this function\n",
        "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
        "    return torch.LongTensor(idxs)\n",
        "\n",
        "all_vocabs = prepare_sequence(list(vocab), word2index).expand(batch_size, voc_size)\n",
        "all_vocabs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOkmxvtjwsa7",
        "outputId": "88b16d62-74b2-4f8c-8352-d25b95c894f0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 4273])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "2YEXpTJJwvZ8"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size     = 10 # mini-batch size\n",
        "embedding_size = 2 #so we can later plot\n",
        "window_size=2\n",
        "model  = Skipgram(voc_size, embedding_size)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "import time\n",
        "\n",
        "# Training\n",
        "start_train_time = time.time()\n",
        "num_epochs = 1000\n",
        "start = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    input_batch, target_batch = random_batch(batch_size, corpus, window_size)\n",
        "    input_batch  = torch.LongTensor(input_batch) #[batch_size, 1]\n",
        "    target_batch = torch.LongTensor(target_batch) #[batch_size, 1]\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss = model(input_batch, target_batch, all_vocabs)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        end = time.time()\n",
        "        epoch_mins, epoch_secs = epoch_time(start, end)\n",
        "        print(f\"Epoch: {epoch + 1} | cost: {loss:.6f} | time: {epoch_mins}m {epoch_secs}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-p_wDgNJw0kJ",
        "outputId": "74f79c2b-64ca-4bb3-f7e5-a83953136d4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 100 | cost: 9.959069 | time: 0m 15s\n",
            "Epoch: 200 | cost: 11.423738 | time: 0m 30s\n",
            "Epoch: 300 | cost: 9.541531 | time: 0m 45s\n",
            "Epoch: 400 | cost: 8.458012 | time: 1m 0s\n",
            "Epoch: 500 | cost: 8.943056 | time: 1m 15s\n",
            "Epoch: 600 | cost: 8.225544 | time: 1m 31s\n",
            "Epoch: 700 | cost: 8.510216 | time: 1m 46s\n",
            "Epoch: 800 | cost: 7.950565 | time: 2m 1s\n",
            "Epoch: 900 | cost: 8.315861 | time: 2m 16s\n",
            "Epoch: 1000 | cost: 9.020043 | time: 2m 31s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embed(word):\n",
        "    id_tensor = torch.LongTensor([word2index[word]])\n",
        "    v_embed = model.embedding_center_word(id_tensor)\n",
        "    u_embed = model.embedding_outside_word(id_tensor) \n",
        "    word_embed = (v_embed + u_embed) / 2 \n",
        "    x, y = word_embed[0][0].item(), word_embed[0][1].item()\n",
        "\n",
        "    return x, y\n",
        "\n",
        "plt.figure(figsize=(6,3))\n",
        "for i, word in enumerate(vocab[:20]): #loop each unique vocab\n",
        "    x, y = get_embed(word)\n",
        "    plt.scatter(x, y)\n",
        "    plt.annotate(word, xy=(x, y), xytext=(5, 2), textcoords='offset points')\n",
        "plt.title('Window size of 2')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "FHQ6O4b3xGRY",
        "outputId": "41df080a-94ea-4756-cc32-0cc9957071ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "path = '/content/Skipgrams_1000.pth'\n",
        "torch.save(model.state_dict(), path)"
      ],
      "metadata": {
        "id": "IAljsP2-0GPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CBOW**\n",
        "\n",
        "Copying everything from 1st assignment"
      ],
      "metadata": {
        "id": "xZlH2kSD0S6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random batch for cbow\n",
        "\n",
        "# Random batch for cbow\n",
        "\n",
        "def random_batch_cbow(batch_size, word_sequence, window_size=1):\n",
        "\n",
        "    cbow = []\n",
        "\n",
        "    for sent in corpus:\n",
        "        for i in range(1, len(sent) - 1): # So we can modify the window size\n",
        "            target = word2index[sent[i]]\n",
        "            context = list()\n",
        "            \n",
        "            for j in range(window_size):\n",
        "                \n",
        "                if i - (j + 1) >= 0: # Check if it outside of range from the left of list\n",
        "                    context.append(word2index[sent[i - (j + 1)]])\n",
        "                \n",
        "                if i + (j + 1) < len(sent): # Check if it outside of range from the right of list\n",
        "                    context.append(word2index[sent[i + (j + 1)]])\n",
        "            \n",
        "            # This part is different from skipgram\n",
        "            # Now we use all context as input and target as label\n",
        "            for w in context:\n",
        "                cbow.append([context, target])\n",
        "    \n",
        "    random_inputs = []\n",
        "    random_labels = []\n",
        "    random_index = np.random.choice(range(len(cbow)), batch_size, replace=False) #randomly pick without replacement\n",
        "    \n",
        "    for i in random_index:\n",
        "        random_inputs.append(cbow[i][0])  # Context word that we want as input\n",
        "        random_labels.append([cbow[i][1]])  # Target word that we want as label\n",
        "    \n",
        "    return np.array(random_inputs), np.array(random_labels)"
      ],
      "metadata": {
        "id": "U5XZMiTY0ViM"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # mini-batch size\n",
        "batch_size = 2\n",
        "input_batch, target_batch = random_batch_cbow(batch_size, corpus, 2)\n",
        "\n",
        "print(\"Input: \", input_batch)\n",
        "print(\"Target: \", target_batch)"
      ],
      "metadata": {
        "id": "YaxpIZt20tAE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0971722b-7593-42db-a014-8a24520c7fb1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:  [[1419 3637 2021 1033]\n",
            " [1085 1263 3734 2114]]\n",
            "Target:  [[3830]\n",
            " [1021]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Cbow(nn.Module):\n",
        "    \n",
        "    def __init__(self, voc_size, emb_size):\n",
        "        super(Cbow, self).__init__()\n",
        "        self.embedding_center_word  = nn.Embedding(voc_size, emb_size)  #is a lookup table mapping all ids in voc_size, into some vector of size emb_size\n",
        "        self.embedding_outside_word = nn.Embedding(voc_size, emb_size)\n",
        "    \n",
        "    def forward(self, center_word, outside_word, all_vocabs):\n",
        "        \n",
        "        #convert them into embedding\n",
        "        center_word_embed  = self.embedding_center_word(center_word)     #(batch_size, 1, emb_size)\n",
        "        outside_word_embed = self.embedding_outside_word(outside_word)   #(batch_size, 1, emb_size)\n",
        "        all_vocabs_embed   = self.embedding_outside_word(all_vocabs)     #(batch_size, voc_size, emb_size)\n",
        "        \n",
        "        #bmm is basically @ or .dot , but across batches (i.e., ignore the batch dimension)\n",
        "        top_term = outside_word_embed.bmm(center_word_embed.transpose(1, 2)).squeeze(2)\n",
        "        #(batch_size, 1, emb_size) @ (batch_size, emb_size, 1) = (batch_size, 1, 1) ===> (batch_size, 1)\n",
        "        \n",
        "        top_term_exp = torch.exp(top_term)  #exp(uo vc)\n",
        "        #(batch_size, 1)\n",
        "        \n",
        "        lower_term = all_vocabs_embed.bmm(center_word_embed.transpose(1, 2)).squeeze(2)\n",
        "         #(batch_size, voc_size, emb_size) @ (batch_size, emb_size, 1) = (batch_size, voc_size, 1) = (batch_size, voc_size)\n",
        "         \n",
        "        lower_term_sum = torch.sum(torch.exp(lower_term), 1) #sum exp(uw vc)\n",
        "        #(batch_size, 1)\n",
        "        \n",
        "        loss_fn = -torch.mean(torch.log(top_term_exp / lower_term_sum))\n",
        "        #(batch_size, 1) / (batch_size, 1) ==mean==> scalar\n",
        "        \n",
        "        return loss_fn"
      ],
      "metadata": {
        "id": "9VzxPbtE0xMz"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size     = 10 # mini-batch size\n",
        "embedding_size = 100 #so we can later plot\n",
        "model = Cbow(voc_size, embedding_size)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "all_vocabs = all_vocabs.to(device)"
      ],
      "metadata": {
        "id": "_PDnq6gM2AEb"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "import time\n",
        "num_epochs = 500\n",
        "start = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    input_batch, target_batch = random_batch_cbow(batch_size, corpus, 1)\n",
        "    input_batch  = torch.LongTensor(input_batch).to(device)  #[batch_size, 1]\n",
        "    target_batch = torch.LongTensor(target_batch).to(device) #[batch_size, 1]\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss = model(input_batch, target_batch, all_vocabs)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        end = time.time()\n",
        "        epoch_mins, epoch_secs = epoch_time(start, end)\n",
        "        print(f\"Epoch: {epoch + 1} | cost: {loss:.6f} | time: {epoch_mins}m {epoch_secs}s\")\n",
        "        start = time.time()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUcKQvFm2Go6",
        "outputId": "6569e78b-0bc7-4f11-8b22-1103ff6c7fd8"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 100 | cost: 34.562569 | time: 0m 11s\n",
            "Epoch: 200 | cost: 24.776230 | time: 0m 10s\n",
            "Epoch: 300 | cost: 32.017139 | time: 0m 10s\n",
            "Epoch: 400 | cost: 30.892143 | time: 0m 14s\n",
            "Epoch: 500 | cost: 29.277050 | time: 0m 13s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving Model**\n"
      ],
      "metadata": {
        "id": "242Nr-m75IOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "path = '/content/CBow_model_500.pth'\n",
        "torch.save(model.state_dict(), path)"
      ],
      "metadata": {
        "id": "PasTsmUr2UGY"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Negative Sampling**"
      ],
      "metadata": {
        "id": "oqX4eT1LNVAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "word_count = Counter(flatten(corpus))\n",
        "num_total_words = sum([c for w, c in word_count.items()])\n"
      ],
      "metadata": {
        "id": "Ha6W_TI55Pb4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create unigram table\n",
        "Z = 0.001\n",
        "unigram_table = []\n",
        "\n",
        "for vo in vocab:\n",
        "    unigram_table.extend([vo] * int(((word_count[vo]/num_total_words)**0.75)/Z))"
      ],
      "metadata": {
        "id": "G8Xa8rq1NbZM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(unigram_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOLGYmwmNd0q",
        "outputId": "5ae2452d-4ff0-462b-bf93-2091ade36b92"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['after', 'after', 'after', 'after', 'after', 'after', 'after', 'known', 'member', 'member', 'set', \"organization's\", 'b.', 'b.', 'university', 'university', 'stand', 'stand', 'then', 'then', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'date', 'residential', 'along', 'along', 'any', 'any', 'any', 'any', 'sponsored', 'little', 'jackson', 'spokesmen', 'court', 'court', 'court', 'court', 'court', 'agreed', 'agreed', 'offenses', 'nomination', 'bank', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'voters', 'voters', 'voters', 'saw', 'greater', 'philadelphia', 'philadelphia', '11', 'certain', 'certain', '$500', 'rev.', 'between', 'between', 'between', 'blue', \"women's\", 'their', 'their', 'their', 'their', 'their', 'their', 'their', 'important', 'prison', 'parsons', 'weeks', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'jim', 'back', 'back', 'back', 'government', 'government', 'government', 'government', 'government', 'government', 'government', 'so', 'so', 'so', 'adc', 'adc', 'voting', 'roberts', '9', 'effective', 'attend', 'school', 'school', 'school', 'school', 'school', 'school', 'reforms', 'brought', 'brought', 'issue', 'issue', 'issue', 'issue', 'morris', 'oppose', 'take', 'take', 'take', 'take', 'take', 'taking', 'about', 'about', 'about', 'about', 'about', \"can't\", 'geneva', 'ready', 'missionary', 'countries', 'countries', 'countries', 'message', 'security', 'security', 'too', 'leadership', 'leadership', 'party', 'party', 'party', 'party', 'party', 'party', 'are', 'are', 'are', 'are', 'are', 'are', 'are', 'are', 'are', 'are', 'are', '1', '1', '1', 'directed', 'revenue', 'chairman', 'chairman', 'chairman', 'increase', 'increase', 'increase', 'increase', 'mr.', 'mr.', 'mr.', 'mr.', 'mr.', 'mr.', 'mr.', 'mr.', 'mr.', 'mr.', 'actions', 'falls', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'zimmerman', 'm.', 'm.', 'either', 'level', 'through', 'through', 'through', 'sunday', 'sunday', 'sunday', 'scheduled', 'scheduled', 'failure', 'ptc', 'days', 'days', 'days', 'earlier', 'choice', 'less', 'followed', 'everything', 'requirement', 'gen.', 'gen.', 'reduce', 'sue', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'plans', 'plans', 'center', 'congressmen', 'open', 'notte', 'issues', 'mention', 'hold', 'says', 'defense', 'defense', 'defense', '18', '18', 'service', 'service', 'service', \"president's\", 'best', 'constitution', 'making', 'even', 'even', 'even', 'thought', 'national', 'national', 'national', 'national', 'airport', 'signatures', 'going', 'discrimination', ';', ';', ';', 'supported', 'views', 'calls', 'calls', 'calls', 'effort', 'effort', 'sound', 'they', 'they', 'they', 'they', 'they', 'they', 'they', 'they', 'they', '200', 'rescue', 'hartsfield', 'conference', 'conference', 'districts', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'crisis', 'favor', 'provide', 'provide', 'provide', 'still', 'still', \"''\", \"''\", \"''\", \"''\", \"''\", \"''\", \"''\", \"''\", \"''\", \"''\", \"''\", \"''\", \"''\", \"''\", \"''\", \"''\", \"''\", \"''\", \"''\", \"''\", \"''\", \"''\", \"''\", \"''\", \"''\", \"''\", \"''\", \"''\", 'which', 'which', 'which', 'which', 'which', 'which', 'which', 'which', 'which', 'which', 'which', 'which', 'p.m.', 'private', 'private', 'counties', 'counties', 'early', 'early', 'floor', 'already', 'better', 'needed', 'soviet', 'soviet', 'leader', 'leader', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', 'eastwick', 'legislation', 'legislation', 'recent', 'recent', 'if', 'if', 'if', 'if', 'if', 'if', 'nursing', 'nursing', 'argued', 'group', 'group', 'interested', 'seats', 'recommended', 'recommended', 'major', 'major', 'sam', 'front', \"georgia's\", 'mississippi', 'department', 'department', 'department', 'department', 'department', 'day', 'day', 'day', 'day', 'religious', 'religious', 'enabling', 'out', 'out', 'out', 'out', 'out', 'out', 'out', 'left', 'left', 'left', 'entering', 'public', 'public', 'public', 'public', 'public', 'our', 'our', 'our', 'offered', 'section', 'rep.', 'rep.', 'until', 'them', 'them', 'them', 'them', 'them', 'bloc', 'without', 'without', 'without', 'army', 'army', 'were', 'were', 'were', 'were', 'were', 'were', 'were', 'last', 'last', 'last', 'last', 'last', 'last', 'last', 'last', 'matching', 'stood', '1961', '1961', '1961', 'all', 'all', 'all', 'all', 'all', 'purchasing', 'cuba', 'hours', 'esplanade', 'ordinance', 'serious', 'budget', 'cook', 'ever', 'contract', '15', 'mind', 'political', 'political', 'political', 'political', \"mayor's\", 'congress', 'congress', 'congress', 'on', 'on', 'on', 'on', 'on', 'on', 'on', 'on', 'on', 'on', 'on', 'on', 'on', 'on', 'on', 'on', 'on', 'on', 'on', 'on', 'on', 'on', 'on', 'on', 'on', 'victory', 'opportunity', 'causes', 'pratt', 'civil', 'civil', 'an', 'an', 'an', 'an', 'an', 'an', 'an', 'an', 'an', 'an', 'an', 'an', 'an', 'an', 'call', 'warden', 'economic', 'economic', 'years', 'years', 'years', 'years', 'years', 'available', 'white', 'white', 'white', 'science', 'patient', 'god', 'god', 'jones', 'jones', 'jones', 'decided', 'decided', 'avenue', 'avenue', 'obtained', 'offer', 'dollars', 'dollars', 'alone', 'asia', 'senators', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', 'water', 'water', 'laos', 'laos', 'laos', 'laos', 'retirement', 'begin', 'amendment', 'june', 'june', 'crime', 'york', 'agencies', 'voted', 'career', 'very', 'very', 'very', 'increased', 'turned', 'assistant', 'assistant', 'special', 'special', 'special', 'special', 'special', 'future', 'future', 'future', 'states', 'states', 'states', 'states', 'states', 'states', 'states', 'controller', 'reama', '13', '13', 'c.', 'c.', 'c.', 'planning', 'teacher', 'there', 'there', 'there', 'there', 'there', 'there', 'there', 'there', 'there', 'latin', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'a.', 'a.', 'a.', 'development', 'development', 'development', 'stage', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', 'ago', 'however', 'however', '``', '``', '``', '``', '``', '``', '``', '``', '``', '``', '``', '``', '``', '``', '``', '``', '``', '``', '``', '``', '``', '``', '``', '``', '``', '``', '``', '``', '``', 'bills', 'bills', 'might', 'might', 'wexler', 'wexler', 'officials', 'meeting', 'meeting', 'meeting', 'meeting', 'source', 'nations', 'nations', 'nations', 'denied', 'faced', \"didn't\", 'teamsters', 'great', 'procedures', 'effect', 'sessions', 'incumbent', 'deaf', 'deaf', 'official', 'how', 'how', 'may', 'may', 'may', 'may', 'radio', 'nov.', 'reports', 'reports', 'judges', 'chief', 'chief', 'listed', 'performance', 'need', 'need', 'need', 'indicated', 'doctor', 'ratcliff', 'also', 'also', 'also', 'also', 'also', 'also', 'also', 'new', 'new', 'new', 'new', 'new', 'new', 'new', 'new', 'new', 'new', 'office', 'office', 'rule', 'rule', 'rule', 'elections', 'feb.', 'questions', 'population', 'population', 'mayor', 'mayor', 'mayor', 'mayor', 'payment', 'like', 'like', 'berger', 'program', 'program', 'program', 'program', 'program', 'program', 'former', 'former', 'former', 'wanted', 'goldberg', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'reaction', 'information', 'information', 'achieve', 'irregularities', 'evidence', 'evidence', 'action', 'action', 'presidential', 'steps', 'steps', 'we', 'we', 'we', 'we', 'we', 'we', 'poll', 'agreement', 'barber', 'provides', 'revenues', 'become', 'become', 'providing', 'vote', 'vote', 'vote', 'vote', 'vote', 'received', 'received', 'college', 'college', 'college', 'highway', 'highway', 'with', 'with', 'with', 'with', 'with', 'with', 'with', 'with', 'with', 'with', 'with', 'with', 'with', 'with', 'with', 'with', 'with', 'points', 'appointed', 'announced', 'announced', 'town', 'town', 'morse', '10', '10', '10', 'find', 'find', 'have', 'have', 'have', 'have', 'have', 'have', 'have', 'have', 'have', 'have', 'have', 'given', 'given', 'given', 'agency', 'controversy', 'needs', 'salem', 'using', 'vital', 'fiscal', 'race', 'race', 'governor', 'governor', 'governor', 'my', 'my', 'capitol', 'southeast', 'ahead', 'charge', 'charge', 'bid', 'series', 'spoke', 'track', 'track', 'married', 'time', 'time', 'time', 'time', 'time', 'measure', 'measure', 'h.', 'clear', 'barnett', 'barnett', 'barnett', 'age', 'personnel', 'recommendations', 'recommendations', 'aid', 'aid', 'aid', 'aid', 'aid', 'proposal', 'proposal', 'proposal', 'fire', 'fire', 'fire', 'fire', 'investigation', 'investigation', 'republicanism', 'order', 'director', 'director', 'director', 'director', 'uncertain', 'gubernatorial', 'gubernatorial', 'really', 'purchase', 'down', 'down', 'act', 'act', 'l.', 'here', 'here', 'here', 'why', 'relations', 'relations', 'e.', 'e.', 'parkhouse', 'daughter', 'hotel', 'hotel', 'hotel', 'toward', 'toward', '23d', 'station', 'informed', 'inside', 'authority', 'authority', 'carry', 'fighters', 'experience', 'bureau', 'responsible', 'young', 'city', 'city', 'city', 'city', 'city', 'city', 'city', 'city', 'city', 'city', 'jersey', 'jersey', 'week', 'week', 'week', 'name', 'goodis', 'money', 'money', 'trenton', 'challenge', 'only', 'only', 'only', 'only', 'cooperation', 'raises', 'served', 'precincts', 'telephone', 'precinct', 'critical', 'westfield', 'think', 'because', 'because', 'because', 'sen.', 'sen.', 'sen.', 'sen.', 'de', 'company', 'company', 'interest', 'square', 'green', 'attended', 'many', 'many', 'many', 'long', 'long', 'long', 'premier', 'dead', 'explosion', 'laws', 'laws', 'methods', 'remark', 'providence', 'providence', 'right', 'right', 'nixon', 'support', 'done', 'done', 'involving', 'preserve', 'affairs', 'march', 'april', 'million', 'million', 'million', 'million', 'million', 'million', 'car', 'me', 'led', 'democrats', 'least', 'sheets', 'cities', 'business', 'business', 'people', 'people', 'people', 'people', 'people', 'thursday', 'thursday', 'payroll', 'payroll', 'difficult', 'come', 'come', 'come', 'senate', 'senate', 'senate', 'senate', 'policies', 'policies', 'conflict', 'person', 'well', 'well', 'sent', 'opposed', '1910', 'citizens', 'citizens', 'life', 'get', 'get', 'get', 'sheeran', 'nevertheless', 'law', 'law', 'law', 'law', 'labor', 'labor', 'reached', 'ierulli', 'term', 'term', 'term', 'island', 'scholarships', 'together', 'aged', 'dental', 'dental', 'according', 'charter', 'charter', 'charter', 'air', 'accept', 'tuesday', 'tuesday', 'tuesday', 'essential', 'running', 'running', 'test', 'again', 'again', 'st.', 'expense', 'africa', 'passed', 'passed', 'passed', 'introduced', 'worth', 'worth', 'just', 'just', 'hemphill', 'hemphill', 'into', 'into', 'into', 'into', 'into', 'every', 'replace', 'much', 'much', 'projects', 'those', 'those', 'those', 'old', 'beame', 'millions', '2', 'cases', 'cases', 'cases', 'foreign', 'foreign', 'speech', 'gov.', 'gov.', 'resolution', 'resolution', 'resolution', '?', '?', '?', 'screvane', 'reported', 'reported', 'reported', 'sign', 'part', 'part', 'merely', 'immediate', 'cotten', 'pace', '65', 'house', 'house', 'house', 'house', 'house', 'house', 'house', 'fight', 'fight', 'later', 'later', 'taxes', 'taxes', 'per', 'per', 'per', 'per', 'co.', 'co.', 'taken', 'taken', 'taken', 'assistance', 'large', 'him', 'him', 'roads', 'coming', 'prices', 'dollar', 'pressure', 'want', 'matter', 'matter', 'step', 'up', 'up', 'up', 'up', 'up', 'up', 'ballot', 'ballot', 'election', 'election', 'election', 'election', 'election', 'election', 'election', 'r.', 'r.', 'council', 'council', 'council', 'council', 'council', 'council', 'third', 'commission', 'commission', 'persons', 'persons', 'persons', 'costs', 'costs', 'added', 'added', 'added', 'field', 'candidacy', 'social', 'social', 'several', 'several', 'several', 'underlying', 'association', 'association', 'association', 'rhode', 'charles', 'charles', 'anonymous', 'must', 'must', 'must', 'must', 'must', 'candidate', 'candidate', 'candidate', 'candidate', \"city's\", 'now', 'now', 'now', 'now', 'now', 'war', 'asked', 'asked', 'asked', 'asked', 'where', 'where', 'where', 'where', 'atlanta', 'each', 'each', 'each', 'each', 'problem', 'problem', 'problem', 'hill', 'gladden', 'concern', 'concern', 'thousands', 'communist', 'communist', 'communist', 'american', 'american', 'consulting', 'berry', 'operation', 'district', 'district', 'district', 'district', 'district', 'say', 'say', 'understanding', 'his', 'his', 'his', 'his', 'his', 'his', 'his', 'his', 'his', 'his', 'his', 'his', 'his', 'his', 'his', 'actually', 'basis', 'education', 'education', 'education', 'education', 'alternative', 'factor', '(', '(', '(', '(', '(', 'way', 'project', 'project', 'project', 'project', 'force', 'named', 'july', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'raising', 'put', 'paying', 'wednesday', 'bond', 'bond', 'bond', 'thus', 'criminal', 'robert', 't.', 'eliminate', 'opposition', 'opposition', 'same', 'same', 'juvenile', 'central', 'central', 'approval', 'highly', 'hawksley', 'hawksley', 'hawksley', 'developed', 'positions', 'county', 'county', 'county', 'county', 'county', 'county', 'county', 'build', 'build', 'aj', 'manner', 'does', 'does', 'present', 'present', 'present', 'sheriff', 'bible', 'further', 'further', 'cost', 'cost', 'cost', 'family', 'today', 'today', 'today', 'scott', \"we'll\", 'she', 'period', 'church', 'church', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'nearly', 'two', 'two', 'two', 'two', 'two', 'two', 'tract', 'industry', 'welfare', 'welfare', 'schools', 'schools', 'schools', 'schools', 'schools', '17', 'soon', 'molvar', 'institute', 'opinion', 'members', 'members', 'members', 'members', 'medical', 'medical', 'medical', 'medical', 'talks', 'w.', 'w.', 'w.', 'organization', 'organization', 'organization', 'request', 's.', 'americans', 'fulton', 'fulton', 'fulton', 'fort', 'prince', 'prince', 'berlin', 'situation', 'help', 'help', 'help', 'eight', 'eight', 'year', 'year', 'year', 'year', 'year', 'year', 'year', 'year', 'year', 'staff', 'proposed', 'proposed', 'proposed', 'firmer', 'mean', 'j.', 'j.', 'j.', 'j.', 'sept.', 'most', 'most', 'most', 'most', 'most', 'meet', 'meet', 'williams', 'nine', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'months', 'months', 'months', 'polls', 'communists', 'communists', 'sales', 'sales', 'sales', 'full', 'full', 'having', 'high', 'high', 'high', 'has', 'has', 'has', 'has', 'has', 'has', 'has', 'has', 'has', 'has', 'has', 'has', 'has', 'has', 'has', 'has', 'has', 'called', 'called', 'called', 'called', 'trucks', 'start', 'eugene', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'clearly', 'predict', 'yet', 'commissioner', 'commissioner', 'could', 'could', 'could', 'could', 'could', 'use', 'use', 'general', 'general', 'general', 'general', 'general', 'representing', 'or', 'or', 'or', 'or', 'or', 'or', 'or', 'or', 'or', 'petitions', 'petitions', 'five', 'five', 'five', 'gop', 'employed', 'massachusetts', 'massachusetts', 'medicine', 'promised', 'another', 'another', 'another', 'while', 'while', 'while', 'boost', 'shortly', 'us', 'estimates', 'means', 'means', 'willing', 'willing', 'follow', 'research', 'research', 'since', 'since', 'since', 'since', 'designed', 'georgia', 'off', 'off', 'by', 'by', 'by', 'by', 'by', 'by', 'by', 'by', 'by', 'by', 'by', 'by', 'by', 'by', 'by', 'by', 'by', 'by', 'by', 'by', 'by', 'by', 'said', 'said', 'said', 'said', 'said', 'said', 'said', 'said', 'said', 'said', 'said', 'said', 'said', 'said', 'said', 'said', 'said', 'said', 'said', 'said', 'said', 'said', 'said', 'said', 'said', 'whether', 'whether', 'whether', 'stores', 'p.', 'grants', 'grants', 'grants', 'spring', 'wagner', 'wagner', 'wagner', 'presented', 'fund', 'legislators', 'legislators', 'legislators', 'carcass', 'bellows', 'original', 'investigate', 'detailed', 'under', 'under', 'under', 'under', 'under', 'west', 'pay', 'pay', 'pay', 'pay', 'america', 'took', 'took', 'areas', 'degree', 'degree', 'likely', 'miss', 'as', 'as', 'as', 'as', 'as', 'as', 'as', 'as', 'as', 'as', 'as', 'as', 'as', 'as', 'as', 'as', 'as', 'as', 'as', 'what', 'what', 'what', 'what', 'what', 'fee', 'division', 'division', 'night', 'night', 'night', 'night', 'houses', 'prevent', 'attorney', 'attorney', 'attorney', 'job', 'workers', 'workers', 'permits', 'committee', 'committee', 'committee', 'committee', 'committee', 'committee', 'committee', 'committee', 'bill', 'bill', 'bill', 'bill', 'bill', 'bill', 'bill', 'bill', 'certainly', 'additional', 'additional', \"governor's\", 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'ward', 'ward', 'own', 'own', '100', 'parties', 'parties', 'secretary', 'secretary', 'secretary', 'secretary', 'international', 'rural', 'rural', 'complete', 'superior', 'churches', 'grover', 'disclosed', 'point', 'point', 'club', 'care', 'care', 'care', 'care', 'required', 'big', 'austin', 'austin', 'red', 'trial', 'trial', 'cabinet', 'charged', 'charged', 'head', 'head', 'employment', 'know', 'know', 'form', 'form', 'jail', 'changes', 'changes', 'revolving', 'upon', 'upon', 'corp.', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'perhaps', 'lives', 'monday', 'monday', 'monday', 'monday', 'decisions', 'parade', 'tax', 'tax', 'tax', 'tax', 'tax', 'tax', 'tax', '$28', 'pro-western', 'who', 'who', 'who', 'who', 'who', 'who', 'who', 'who', 'who', 'who', 'who', 'who', 'generally', 'personal', 'texas', 'texas', 'texas', 'texas', 'texas', '16', 'phouma', 'statements', 'statements', 'wayne', 'event', 'washington', 'washington', 'washington', 'washington', 'felt', 'side', ')', ')', ')', ')', ')', 'pointed', 'buildings', 'leading', 'administration', 'administration', 'administration', 'administration', 'administration', 'administration', 'administration', 'administration', 'administration', 'administration', 'lao', 'tomorrow', 'dallas', 'dallas', 'dallas', 'constitutional', 'health', 'health', 'health', 'redevelopment', \"nation's\", 'some', 'some', 'some', 'some', 'some', 'some', 'some', 'some', 'some', 'constituted', 'ones', 'bankers', 'allowed', '8', 'its', 'its', 'its', 'its', 'its', 'its', 'its', 'its', 'building', 'builders', 'assembly', 'assembly', 'plan', 'plan', 'plan', 'plan', 'plan', 'plan', 'plan', 'pathet', 'richard', 'richard', 'good', 'see', 'see', 'see', 'retired', 'deal', 'bring', 'rate', 'judge', 'judge', 'judge', 'barnard', 'do', 'do', 'do', 'legislative', 'problems', 'problems', 'formula', 'nato', 'nato', 'something', 'd.', 'd.', 'kansas', 'question', 'question', 'being', 'being', 'being', 'being', 'growth', 'railroad', 'leaders', 'leaders', 'leaders', 'none', 'east', 'east', 'seven', 'enforcement', 'january', 'corps', 'corps', 'semester', 'union', 'union', 'martinelli', 'martinelli', 'estimated', 'annual', 'annual', 'able', 'able', 'vandiver', 'spent', '12', 'f.', 'f.', 'basic', 'over', 'over', 'over', 'over', 'over', 'primary', 'primary', 'primary', 'home', 'home', 'home', 'home', 'home', 'home', 'segregation', 'establishment', 'fees', 'fees', 'fees', 'proposals', 'commented', 'amount', 'amount', 'cd', 'cd', 'necessary', 'country', 'funds', 'funds', 'funds', 'funds', 'defeated', 'view', 'work', 'work', 'work', 'work', 'work', 'socialist', 'socialist', 'strong', 'did', 'did', 'did', 'did', 'forces', 'forces', 'lines', 'previous', 'apparent', 'end', 'will', 'will', 'will', 'will', 'will', 'will', 'will', 'will', 'will', 'will', 'will', 'will', 'will', 'will', 'will', 'will', 'will', 'came', 'came', 'pelham', 'attempt', 'kennedy', 'kennedy', 'kennedy', 'kennedy', 'kennedy', 'u.', 'banks', 'howard', 'el', 'congressional', 'congressional', 'sandman', 'appointment', 'appointment', 'george', 'voluntary', 'others', 'subject', 'meyner', 'higher', 'real', 'press', 'movement', '24', '24', 'william', 'william', 'despite', 'mitchell', 'mitchell', 'mitchell', 'suit', 'replied', 'housing', 'ways', 'you', 'you', 'largest', 'executive', 'executive', 'hospital', 'hospital', 'hospital', 'bronx', 'but', 'but', 'but', 'but', 'but', 'but', 'but', 'but', 'but', 'but', 'but', 'speaker', 'enough', 'enough', 'rules', 'got', 'concerned', 'gursel', 'fact', 'dinner', 'declared', 'declared', 'delegates', 'elected', 'elected', 'ticket', 'nuclear', 'approved', 'approved', 'past', 'past', 'whom', 'formally', '1959', 'paid', 'paid', 'believes', 'populous', 'session', 'session', 'session', 'session', 'session', 'billion', 'principal', ':', ':', ':', ':', ':', 'jr.', 'jr.', 'during', 'during', 'during', 'keeping', 'including', '70', 'raised', 'eliminating', 'pfaff', 'ask', 'ask', 'wife', 'following', 'following', '35', 'ranged', 'should', 'should', 'should', 'should', 'should', 'should', 'next', 'next', 'traffic', 'local', 'local', 'local', 'local', 'belief', 'children', 'children', 'services', 'services', 'souvanna', 'board', 'board', 'board', 'board', 'board', 'involved', 'involved', 'land', 'case', 'case', 'case', 'post', 'grand', 'grand', 'report', 'report', 'report', 'raymond', 'joint', 'resentment', 'jan.', 'notice', 'position', 'minister', 'peace', 'teaching', 'finance', 'advantage', 'make', 'make', 'make', 'make', 'seemed', 'usual', 'issued', 'passing', 'junta', 'karns', 'karns', 'warning', 'martin', 'martin', 'houston', 'hand', 'had', 'had', 'had', 'had', 'had', 'had', 'had', 'had', 'had', 'himself', 'solicitor', '1958', 'conservation', 'companies', 'henry', 'portland', 'candidates', 'candidates', 'candidates', 'within', 'within', 'first', 'first', 'first', 'first', 'first', 'first', 'system', 'system', 'system', 'can', 'can', 'can', 'can', 'can', \"'\", \"'\", \"'\", \"'\", 'modest', 'direction', 'small', 'trouble', 'politicians', 'paris', 'filed', 'pennsylvania', 'kept', 'beliefs', 'establish', 'area', 'move', 'run', 'run', 'democratic', 'democratic', 'democratic', 'democratic', 'democratic', 'democratic', 'democratic', 'military', 'military', 'military', 'friday', 'friday', 'friday', 'address', 'address', 'expects', 'orleans', 'apparently', 'apparently', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'six', 'six', \"council's\", 'obtain', 'thing', 'groups', 'groups', 'mates', 'one', 'one', 'one', 'one', 'one', 'one', 'one', 'one', 'one', 'one', 'man', 'man', 'man', 'john', 'john', 'never', 'facilities', 'petition', 'told', 'told', 'told', 'told', 'provided', \"rusk's\", 'insurance', 'far', 'far', 'far', 'johnston', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'bush', 'hardly', 'practices', 'child', 'number', 'number', 'representatives', '4', '4', 'bids', 'dr.', 'dr.', 'dr.', 'transition', 'go', 'go', 'go', 'community', 'community', 'advisory', 'police', 'police', 'lawyer', 'adopted', 'face', 'legislature', 'legislature', 'legislature', 'legislature', 'legislature', 'jury', 'jury', 'jury', 'jury', 'jury', 'contributions', \"year's\", 'mrs.', 'mrs.', 'dog', 'working', 'historic', 'regular', 'world', 'ave.', \"state's\", 'clark', 'clark', \"i'm\", 'licenses', 'programs', 'frank', 'delinquency', 'state', 'state', 'state', 'state', 'state', 'state', 'state', 'state', 'state', 'state', 'state', 'state', 'state', 'state', 'state', 'homes', 'assemblies', 'superintendent', 'superintendent', 'ordinary', 'half', 'half', 'headed', 'regime', 'three', 'three', 'three', 'three', 'revision', 'full-time', 'full-time', 'president', 'president', 'president', 'president', 'president', 'president', 'president', 'president', 'president', 'president', 'would', 'would', 'would', 'would', 'would', 'would', 'would', 'would', 'would', 'would', 'would', 'would', 'would', 'would', 'would', 'would', 'would', 'would', 'would', 'would', 'would', 'policy', 'policy', 'study', 'study', 'free', 'fair', 'made', 'made', 'made', 'made', 'made', 'made', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'grant', 'grant', 'firm', 'firm', 'construction', 'construction', 'daniel', 'bourcier', 'attack', 'attack', 'attack', 'tell', 'hughes', 'hughes', 'hughes', 'hughes', 'hughes', 'women', 'minor', '3', 'among', 'among', '30', 'against', 'against', 'against', 'against', 'debate', 'history', 'audience', 'suggested', 'held', 'recommend', 'give', 'give', 'give', 'kind', 'heard', 'defendants', 'similar', 'similar', 'oslo', 'before', 'before', 'before', 'went', 'seek', 'termed', 'alliance', 'efforts', 'efforts', 'efforts', 'record', 'found', 'campaign', 'campaign', 'campaign', 'campaign', 'oklahoma', 'pass', '20', 'hotels', 'federal', 'federal', 'federal', 'federal', 'federal', 'g.', '7', 'residents', 'almost', 'confidence', 'expected', 'expected', 'expected', 'expected', 'expected', 'themselves', 'themselves', 'more', 'more', 'more', 'more', 'more', 'more', 'more', 'more', 'more', 'more', 'urged', 'license', 'hear', 'four', 'four', 'maximum', 'votes', 'instead', 'bonds', 'bonds', 'allen', 'was', 'was', 'was', 'was', 'was', 'was', 'was', 'was', 'was', 'was', 'was', 'was', 'was', 'was', 'was', 'was', 'was', 'was', 'was', 'was', 'was', 'was', 'davis', 'davis', 'davis', 'joe', 'resigned', 'such', 'such', 'such', 'such', 'such', 'representative', 'possible', 'possible', 'possible', 'receive', 'receive', 'feel', 'brooklyn', 'place', 'place', 'both', 'both', 'both', 'both', 'coalition', 'coalition', 'moving', 'these', 'these', 'these', 'these', 'these', 'republicans', 'republicans', 'republicans', 'republican', 'republican', 'republican', 'republican', 'republican', 'placed', 'this', 'this', 'this', 'this', 'this', 'this', 'this', 'this', 'this', 'this', 'this', 'this', 'this', 'this', 'control', 'property', 'property', 'caused', 'posts', 'november', 'november', 'than', 'than', 'than', 'than', 'than', 'than', 'than', 'statement', 'statement', 'united', 'united', 'united', 'united', 'united', 'united', 'junior', 'battle', 'battle', 'yesterday', 'yesterday', 'yesterday', 'studied', 'unspecified', 'explained', 'unity', 'boston', 'eisenhower', 'eisenhower', 'eisenhower', 'buckley', 'buckley', 'cent', 'cent', 'cent', 'i', 'i', 'i', 'i', 'i', 'i', 'at', 'at', 'at', 'at', 'at', 'at', 'at', 'at', 'at', 'at', 'at', 'at', 'at', 'at', 'at', 'hearing', 'hearing', 'when', 'when', 'when', 'when', 'when', 'courses', 'senator', 'james', 'james', 'james', 'limited', 'cannot']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def prepare_sequence(seq, word2index):\n",
        "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
        "    return torch.LongTensor(idxs)\n",
        "\n",
        "def negative_sampling(targets, unigram_table, k):\n",
        "    batch_size = targets.size(0)\n",
        "    neg_samples = []\n",
        "    for i in range(batch_size):\n",
        "        nsample = []\n",
        "        target_index = targets[i].item()\n",
        "        while len(nsample) < k: # num of sampling\n",
        "            neg = random.choice(unigram_table)\n",
        "            if word2index[neg] == target_index:\n",
        "                continue\n",
        "            nsample.append(neg)\n",
        "        neg_samples.append(prepare_sequence(nsample, word2index).view(1, -1))\n",
        "    \n",
        "    return torch.cat(neg_samples)"
      ],
      "metadata": {
        "id": "qNdiLaJVN1XI"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SkipgramNegSampling(nn.Module):\n",
        "    \n",
        "    def __init__(self, voc_size, emb_size):\n",
        "        super(SkipgramNegSampling, self).__init__()\n",
        "        self.embedding_center_word  = nn.Embedding(voc_size, emb_size)\n",
        "        self.embedding_outside_word = nn.Embedding(voc_size, emb_size)\n",
        "        self.logsigmoid = nn.LogSigmoid()\n",
        "        \n",
        "    def forward(self, center_words, outside_words, negative_words):\n",
        "        #center_words, outside_words: (batch_size, 1)\n",
        "        #negative_words:  (batch_size, k)\n",
        "        \n",
        "        center_embed  = self.embedding_center_word(center_words)    #(batch_size, 1, emb_size)\n",
        "        outside_embed = self.embedding_outside_word(outside_words)  #(batch_size, 1, emb_size)\n",
        "        neg_embed     = self.embedding_outside_word(negative_words) #(batch_size, k, emb_size)\n",
        "        \n",
        "        uovc          =  outside_embed.bmm(center_embed.transpose(1, 2)).squeeze(2)  #(batch_size, 1)\n",
        "        ukvc          = -neg_embed.bmm(center_embed.transpose(1, 2)).squeeze(2)  #(batch_size, k)\n",
        "        ukvc_sum      =  torch.sum(ukvc, 1).view(-1, 1) #(batch_size, 1)\n",
        "        \n",
        "        loss = self.logsigmoid(uovc) + self.logsigmoid(ukvc_sum)  #(batch_size, 1) + (batch_size, 1)\n",
        "                \n",
        "        return -torch.mean(loss)  #scalar, loss should be scalar, to call backward()"
      ],
      "metadata": {
        "id": "6saXwIygOKwE"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize parameter\n",
        "batch_size     = 10 # mini-batch size\n",
        "embedding_size = 100 #so we can later plot\n",
        "model          = SkipgramNegSampling(voc_size, embedding_size)\n",
        "num_neg        = 10 # num of negative sampling\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "SiY35pDsOR2k"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start_train_time = time.time()\n",
        "\n",
        "# Training\n",
        "num_epochs = 1000\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    start = time.time()\n",
        "    \n",
        "    input_batch, target_batch = random_batch(batch_size, corpus, 2)\n",
        "    \n",
        "    #input_batch: [batch_size, 1]\n",
        "    input_batch = torch.LongTensor(input_batch)\n",
        "    \n",
        "    #target_batch: [batch_size, 1]\n",
        "    target_batch = torch.LongTensor(target_batch)\n",
        "    \n",
        "    #negs_batch:   [batch_size, num_neg]\n",
        "    negs_batch = negative_sampling(target_batch, unigram_table, num_neg)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "        \n",
        "    loss = model(input_batch, target_batch, negs_batch)\n",
        "    \n",
        "    end = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start, end)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print(f\"Epoch: {epoch + 1} | cost: {loss:.6f} | time: {epoch_mins}m {epoch_secs}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzsRgw_3OVED",
        "outputId": "f8dfabe1-fa4c-4b14-dbd6-c0c8aecb1869"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 100 | cost: 15.262489 | time: 0m 0s\n",
            "Epoch: 200 | cost: 19.257448 | time: 0m 0s\n",
            "Epoch: 300 | cost: 16.329243 | time: 0m 0s\n",
            "Epoch: 400 | cost: 9.641607 | time: 0m 0s\n",
            "Epoch: 500 | cost: 16.024637 | time: 0m 0s\n",
            "Epoch: 600 | cost: 9.736855 | time: 0m 0s\n",
            "Epoch: 700 | cost: 11.180909 | time: 0m 0s\n",
            "Epoch: 800 | cost: 32.525230 | time: 0m 0s\n",
            "Epoch: 900 | cost: 14.299477 | time: 0m 0s\n",
            "Epoch: 1000 | cost: 21.399591 | time: 0m 0s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "path = '/content/Neg_Skipgrams_1000.pth'\n",
        "torch.save(model.state_dict(), path)"
      ],
      "metadata": {
        "id": "_40nQ5_ROm7u"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing**"
      ],
      "metadata": {
        "id": "XzTAeRsLP4oZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "def read_data(path):\n",
        "    file = open(path, 'r') # Dataset from amamda\n",
        "    contents = file.read()\n",
        "    contents = contents.split('\\n') # Seperate chunk of text into substring\n",
        "    file.close()\n",
        "    return contents\n",
        "\n",
        "path = '/content/questions-words.txt'\n",
        "text = read_data(path)\n",
        "print(text[0:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLaJeJ7UPxmz",
        "outputId": "7eeeddda-130c-41ed-d2eb-872cce1c4beb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[': capital-common-countries', 'Athens Greece Baghdad Iraq', 'Athens Greece Bangkok Thailand', 'Athens Greece Beijing China', 'Athens Greece Berlin Germany', 'Athens Greece Bern Switzerland', 'Athens Greece Cairo Egypt', 'Athens Greece Canberra Australia', 'Athens Greece Hanoi Vietnam', 'Athens Greece Havana Cuba']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Find the seperator name and index**"
      ],
      "metadata": {
        "id": "T6Ia3qpTQn4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seperator = [(idx, sent) for idx, sent in enumerate(text) if sent[0] == ':']\n",
        "seperator "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGauVngiQYz8",
        "outputId": "d66d407f-90ad-4dc7-ddfb-c47b74eeebd1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, ': capital-common-countries'),\n",
              " (507, ': capital-world'),\n",
              " (5032, ': currency'),\n",
              " (5899, ': city-in-state'),\n",
              " (8367, ': family'),\n",
              " (8874, ': gram1-adjective-to-adverb'),\n",
              " (9867, ': gram2-opposite'),\n",
              " (10680, ': gram3-comparative'),\n",
              " (12013, ': gram4-superlative'),\n",
              " (13136, ': gram5-present-participle'),\n",
              " (14193, ': gram6-nationality-adjective'),\n",
              " (15793, ': gram7-past-tense'),\n",
              " (17354, ': gram8-plural'),\n",
              " (18687, ': gram9-plural-verbs')]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's use comparative and nationality-adjective\n",
        "comparative = text[10681:12012]\n",
        "nationality = text[14194:15793]\n",
        "\n",
        "# Concatenate\n",
        "test_text = comparative + nationality\n",
        "\n",
        "# Checking\n",
        "print(test_text[0])\n",
        "print(test_text[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3-7_KwTQq4w",
        "outputId": "65f9c64a-4768-45ec-a64b-0e01aa578127"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bad worse big bigger\n",
            "Ukraine Ukrainian Switzerland Swiss\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Now split the words\n",
        "test_comparative = [sent.split(\" \") for sent in comparative]\n",
        "test_nationality = [sent.split(\" \") for sent in nationality]\n",
        "test_corpus = [sent.split(\" \") for sent in test_text]\n",
        "print(test_corpus[0:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwIv6CkWRUwy",
        "outputId": "2844d1cf-0301-4697-f717-28f2fe366793"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['bad', 'worse', 'big', 'bigger'], ['bad', 'worse', 'bright', 'brighter'], ['bad', 'worse', 'cheap', 'cheaper'], ['bad', 'worse', 'cold', 'colder'], ['bad', 'worse', 'cool', 'cooler']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Flatten and get Unique words**"
      ],
      "metadata": {
        "id": "gGPHZkLKR9id"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "test_vocab = list(set(flatten(test_corpus)))\n",
        "test_vocab[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOFjsH00RzUk",
        "outputId": "65b5e3ef-26f7-4975-f455-efb32f08828c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Icelandic', 'Moldova', 'Chile', 'stronger', 'Brazil']"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_word2index = dict()\n",
        "test_word2index.update({\"<UNK>\":  0})\n",
        "for idx, v in enumerate(test_vocab):\n",
        "        test_word2index.update({v:  idx + 1})\n",
        "\n",
        "test_vocab.append('<UNK>')\n",
        "\n",
        "test_index2word = {v:k for k, v in test_word2index.items()}"
      ],
      "metadata": {
        "id": "urlO-GYXR7lH"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function to get embedding**"
      ],
      "metadata": {
        "id": "lJ9fbW4HStss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embed(word, current_model):\n",
        "    try:\n",
        "        index = word2index[word]\n",
        "    except :\n",
        "        index = word2index['<UNK>'] #unknown\n",
        "    word = torch.LongTensor([index])\n",
        "    \n",
        "    embed =  (current_model.embedding_v(word)+current_model.embedding_u(word))/2\n",
        "    return np.array(embed[0].detach().numpy())"
      ],
      "metadata": {
        "id": "BoPMJGJGSkZk"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def cos_sim(a, b):\n",
        "    cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
        "    return cos_sim"
      ],
      "metadata": {
        "id": "3W4MnIy1SwNP"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_analogy(a,b,c, current_model,vocabs=vocab):\n",
        "    emb_a, emb_b, emb_c = get_embed(a, current_model), get_embed(b, current_model), get_embed(c, current_model)\n",
        "    vector = emb_b - emb_a + emb_c\n",
        "    similarity = -1 \n",
        "    \n",
        "    for vocab in vocabs:\n",
        "        if vocab not in [a,b,c]: #ignore input words itself\n",
        "            current_sim = cos_sim(vector,get_embed(vocab, current_model))\n",
        "            if current_sim > similarity:\n",
        "                similarity = current_sim #update better one\n",
        "                d = (vocab, similarity)\n",
        "    return d"
      ],
      "metadata": {
        "id": "bV3nt_VOS4hu"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "current_model = GloVe(voc_size, embedding_size)\n",
        "current_model.load_state_dict(torch.load('/content/Glove_5000.pth'))\n",
        "current_model.eval()\n",
        "#find_analogy('man', 'woman', 'adult')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKtNVMl0TGnl",
        "outputId": "56b285d3-c428-45fb-c0cb-58b33f23b282"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GloVe(\n",
              "  (embedding_v): Embedding(4273, 100)\n",
              "  (embedding_u): Embedding(4273, 100)\n",
              "  (v_bias): Embedding(4273, 1)\n",
              "  (u_bias): Embedding(4273, 1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_embed = get_embed('good', current_model)"
      ],
      "metadata": {
        "id": "Zb1Yk4xoT66O"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_embed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3RVVl5GT_mr",
        "outputId": "971f2658-0f86-4542-98bc-eb17a1ba83e4"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.05750549, -0.16518529,  0.53817827, -0.0743229 ,  1.721066  ,\n",
              "       -0.10337168, -0.97622836, -0.1463296 ,  0.3981204 ,  0.19209267,\n",
              "       -0.4529785 , -1.1922284 , -0.60328484,  0.84476286,  0.08506405,\n",
              "        0.6684439 , -0.06805685, -0.548988  , -0.2610401 ,  1.2241261 ,\n",
              "       -0.12974629, -1.0905304 ,  0.38937962, -0.0477578 , -0.37867856,\n",
              "        0.24111071,  0.29999048,  0.64772016, -0.2629413 , -0.04437515,\n",
              "        0.85509324,  0.41944277,  0.0048731 , -0.75252914,  0.7442796 ,\n",
              "       -0.83230984,  1.4986928 , -0.72606933,  0.45738572,  0.87141746,\n",
              "       -1.6333348 , -0.57801944,  0.62597513, -0.16132307,  0.9539615 ,\n",
              "       -0.9647589 ,  0.37832868,  0.13204916, -0.38291058,  0.2807761 ,\n",
              "       -0.22834037, -0.29457176,  0.33706522, -0.40950483,  1.2025487 ,\n",
              "       -0.1164791 ,  1.4171383 , -0.9979413 ,  0.5807188 , -0.9665699 ,\n",
              "        0.7063676 , -0.24104436,  0.95203143,  0.16032602, -0.6191424 ,\n",
              "        0.6847868 ,  0.52519435,  0.57415366, -0.3356182 ,  0.8113811 ,\n",
              "        1.1514966 ,  0.25794345,  0.47199002, -0.6627539 , -0.5985563 ,\n",
              "        0.4560126 ,  0.95307195,  0.41291806,  1.6211972 ,  0.12516373,\n",
              "        0.3225025 , -1.5301716 ,  0.25015485, -0.36596316,  0.6470003 ,\n",
              "       -0.42373496,  0.43070942, -1.1690004 ,  1.046476  ,  0.7134719 ,\n",
              "        0.21508527, -0.07226959, -0.38140422, -1.5476835 , -0.04839686,\n",
              "        0.9295937 , -0.2969423 ,  0.8008231 , -0.18983072,  0.42294854],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "find_analogy('good', 'better', 'man',current_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9tDRgjyUMoj",
        "outputId": "9ae7f652-41b8-43bf-8f1f-4ea43f50d7e7"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('married', 0.3612438)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now Trying to do semantic and syntactic Testing using Glove Model**"
      ],
      "metadata": {
        "id": "sPTdOXWwUgrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_accruacy(y, yhat):\n",
        "    if y == yhat:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def test_accruacy_batch(data, current_model):\n",
        "    counter = 0\n",
        "    for sent in data:\n",
        "        label = sent[-1]\n",
        "        a, b, c = sent[:-1]\n",
        "        yhat = find_analogy(a, b, c,current_model)[0] # It's return in tuple form, so we need to slice to get word\n",
        "        if check_accruacy(label, yhat) == True:\n",
        "            counter = counter + 1\n",
        "    \n",
        "    return counter"
      ],
      "metadata": {
        "id": "r8Xx1Ai2WjVt"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "current_model = GloVe(voc_size, embedding_size)\n",
        "current_model.load_state_dict(torch.load('/content/Glove_5000.pth'))\n",
        "current_model.eval()\n",
        "\n",
        "test_list = [test_comparative, test_nationality]\n",
        "test_list_name = ['test_comparative', 'test_nationality']\n",
        "\n",
        "for idx, current_test in enumerate(test_list):\n",
        "   sample_list = random.choices(current_test, k=100)\n",
        "   print(f'Current_test = {test_list_name[idx]}')\n",
        "   accruacy = test_accruacy_batch(sample_list, current_model)\n",
        "   print(accruacy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9YbInC2Viif",
        "outputId": "038dc6a2-a04a-4abb-90da-749dd224ac1e"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current_test = test_comparative\n",
            "0\n",
            "Current_test = test_nationality\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now Trying to do semantic and syntactic Testing using Skipgram Model**"
      ],
      "metadata": {
        "id": "rD0P3SrcXGVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embed(word, current_model):\n",
        "    try:\n",
        "        index = word2index[word]\n",
        "    except :\n",
        "        index = word2index['<UNK>'] #unknown\n",
        "    word = torch.LongTensor([index])\n",
        "    \n",
        "    embed =  (current_model.embedding_center_word(word)+current_model.embedding_outside_word (word))/2\n",
        "    return np.array(embed[0].detach().numpy())"
      ],
      "metadata": {
        "id": "kwMki7UkYfSv"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 2\n",
        "current_model = Skipgram(voc_size, embedding_size)\n",
        "current_model.load_state_dict(torch.load('/content/Skipgrams_1000.pth'))\n",
        "current_model.eval()\n",
        "\n",
        "test_list = [test_comparative, test_nationality]\n",
        "test_list_name = ['test_comparative', 'test_nationality']\n",
        "\n",
        "for idx, current_test in enumerate(test_list):\n",
        "   sample_list = random.choices(current_test, k=100)\n",
        "   print(f'Current_test = {test_list_name[idx]}')\n",
        "   accruacy = test_accruacy_batch(sample_list, current_model)\n",
        "   print(accruacy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2NAfFDHW-5z",
        "outputId": "e2bc184c-5822-40ff-db87-7480f68fe865"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current_test = test_comparative\n",
            "0\n",
            "Current_test = test_nationality\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**semantic and syntactic Testing using Skipgram Model**"
      ],
      "metadata": {
        "id": "ivXUPnHIZM_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 100\n",
        "current_model = Cbow(voc_size, embedding_size)\n",
        "current_model.load_state_dict(torch.load('/content/CBow_model_500.pth'))\n",
        "current_model.eval()\n",
        "\n",
        "test_list = [test_comparative, test_nationality]\n",
        "test_list_name = ['test_comparative', 'test_nationality']\n",
        "\n",
        "for idx, current_test in enumerate(test_list):\n",
        "   sample_list = random.choices(current_test, k=100)\n",
        "   print(f'Current_test = {test_list_name[idx]}')\n",
        "   accruacy = test_accruacy_batch(sample_list, current_model)\n",
        "   print(accruacy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgEIClvnY3UJ",
        "outputId": "e5e594a9-b29d-40ea-82b5-6f2f0dcd1412"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current_test = test_comparative\n",
            "0\n",
            "Current_test = test_nationality\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**semantic and syntactic Testing using Skipgram Negative Sampling Model**"
      ],
      "metadata": {
        "id": "xMn6BPnWZp3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 100\n",
        "current_model = SkipgramNegSampling(voc_size, embedding_size)\n",
        "current_model.load_state_dict(torch.load('/content/Neg_Skipgrams_1000.pth'))\n",
        "current_model.eval()\n",
        "\n",
        "test_list = [test_comparative, test_nationality]\n",
        "test_list_name = ['test_comparative', 'test_nationality']\n",
        "\n",
        "for idx, current_test in enumerate(test_list):\n",
        "   sample_list = random.choices(current_test, k=100)\n",
        "   print(f'Current_test = {test_list_name[idx]}')\n",
        "   accruacy = test_accruacy_batch(sample_list, current_model)\n",
        "   print(accruacy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NKvJidtY3aY",
        "outputId": "c72bd934-381c-4c22-be1b-c89ad1762ee9"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current_test = test_comparative\n",
            "0\n",
            "Current_test = test_nationality\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Synthetic testing**"
      ],
      "metadata": {
        "id": "IOWhOf1SarMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#trying to look syntatic dataset with python file\n",
        "# Import datasets\n",
        "import pandas as pd\n",
        "path = '/content/wordsim_similarity_goldstandard.txt'\n",
        "df = pd.read_table(path, header=None)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "KexYo1Shbw2B",
        "outputId": "9a8f2e28-af0d-4aa4-9b5b-e2c1775f2005"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0      1      2\n",
              "0       tiger    cat   7.35\n",
              "1       tiger  tiger  10.00\n",
              "2       plane    car   5.77\n",
              "3       train    car   6.31\n",
              "4  television  radio   6.77"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0413ed74-a992-45b1-b3e9-1209b4a10dc9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tiger</td>\n",
              "      <td>cat</td>\n",
              "      <td>7.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tiger</td>\n",
              "      <td>tiger</td>\n",
              "      <td>10.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>plane</td>\n",
              "      <td>car</td>\n",
              "      <td>5.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train</td>\n",
              "      <td>car</td>\n",
              "      <td>6.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>television</td>\n",
              "      <td>radio</td>\n",
              "      <td>6.77</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0413ed74-a992-45b1-b3e9-1209b4a10dc9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0413ed74-a992-45b1-b3e9-1209b4a10dc9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0413ed74-a992-45b1-b3e9-1209b4a10dc9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "synthetic_test_set = df.iloc[:20]\n",
        "synthetic_test_set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "W0NHg0Rbb5Wf",
        "outputId": "128e1ab7-43d0-487e-9c34-9d5d69c3f490"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             0           1      2\n",
              "0        tiger         cat   7.35\n",
              "1        tiger       tiger  10.00\n",
              "2        plane         car   5.77\n",
              "3        train         car   6.31\n",
              "4   television       radio   6.77\n",
              "5        media       radio   7.42\n",
              "6        bread      butter   6.19\n",
              "7     cucumber      potato   5.92\n",
              "8       doctor       nurse   7.00\n",
              "9    professor      doctor   6.62\n",
              "10     student   professor   6.81\n",
              "11       smart      stupid   5.81\n",
              "12        wood      forest   7.73\n",
              "13       money        cash   9.15\n",
              "14        king       queen   8.58\n",
              "15        king        rook   5.92\n",
              "16      bishop       rabbi   6.69\n",
              "17        fuck         sex   9.44\n",
              "18    football      soccer   9.03\n",
              "19    football  basketball   6.81"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2758d1bf-68fd-4604-8736-ecbd9d91932e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tiger</td>\n",
              "      <td>cat</td>\n",
              "      <td>7.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tiger</td>\n",
              "      <td>tiger</td>\n",
              "      <td>10.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>plane</td>\n",
              "      <td>car</td>\n",
              "      <td>5.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train</td>\n",
              "      <td>car</td>\n",
              "      <td>6.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>television</td>\n",
              "      <td>radio</td>\n",
              "      <td>6.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>media</td>\n",
              "      <td>radio</td>\n",
              "      <td>7.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>bread</td>\n",
              "      <td>butter</td>\n",
              "      <td>6.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>cucumber</td>\n",
              "      <td>potato</td>\n",
              "      <td>5.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>doctor</td>\n",
              "      <td>nurse</td>\n",
              "      <td>7.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>professor</td>\n",
              "      <td>doctor</td>\n",
              "      <td>6.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>student</td>\n",
              "      <td>professor</td>\n",
              "      <td>6.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>smart</td>\n",
              "      <td>stupid</td>\n",
              "      <td>5.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>wood</td>\n",
              "      <td>forest</td>\n",
              "      <td>7.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>money</td>\n",
              "      <td>cash</td>\n",
              "      <td>9.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>king</td>\n",
              "      <td>queen</td>\n",
              "      <td>8.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>king</td>\n",
              "      <td>rook</td>\n",
              "      <td>5.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>bishop</td>\n",
              "      <td>rabbi</td>\n",
              "      <td>6.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>fuck</td>\n",
              "      <td>sex</td>\n",
              "      <td>9.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>football</td>\n",
              "      <td>soccer</td>\n",
              "      <td>9.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>football</td>\n",
              "      <td>basketball</td>\n",
              "      <td>6.81</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2758d1bf-68fd-4604-8736-ecbd9d91932e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2758d1bf-68fd-4604-8736-ecbd9d91932e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2758d1bf-68fd-4604-8736-ecbd9d91932e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_x1 = synthetic_test_set[0]\n",
        "input_x2 = synthetic_test_set[1]\n",
        "label = synthetic_test_set[2]\n"
      ],
      "metadata": {
        "id": "RNnyPlj3cAVZ"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embed(word, current_model):\n",
        "    try:\n",
        "        index = word2index[word]\n",
        "    except :\n",
        "        index = word2index['<UNK>'] #unknown\n",
        "    word = torch.LongTensor([index])\n",
        "    \n",
        "    embed =  (current_model.embedding_v(word)+current_model.embedding_u(word))/2\n",
        "    return np.array(embed[0].detach().numpy())"
      ],
      "metadata": {
        "id": "LlRPVT-QcMPs"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "current_model = GloVe(voc_size, embedding_size)\n",
        "current_model.load_state_dict(torch.load('/content/Glove_5000.pth'))\n",
        "current_model.eval()\n",
        "\n",
        "test_list = [test_comparative, test_nationality]\n",
        "test_list_name = ['test_comparative', 'test_nationality']\n",
        "\n",
        "results = []\n",
        "for idx in range(20): # We test with only fix 10 samples\n",
        "    emb_x1 = get_embed(input_x1[idx], current_model)\n",
        "    emb_x2 = get_embed(input_x2[idx], current_model)\n",
        "    yhat = stats.spearmanr(emb_x1, emb_x2)\n",
        "    yhat = yhat[0]\n",
        "    #print(yhat)\n",
        "    results.append(yhat)\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "BQrTE0bBc3L7"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdTKMZC-dVDw",
        "outputId": "b698a1ec-5c60-4835-dc2b-5356da40d941"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9999999999999999, 0.9999999999999999, 0.13777377737773777, 0.13777377737773777, -0.1195319531953195, -0.10435043504350434, 0.9999999999999999, 0.9999999999999999, -0.06871887188718871, -0.018577857785778577, -0.13172517251725172, 0.9999999999999999, 0.06568256825682568, -0.050561056105610555, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, -0.04604860486048604, 0.20056405640564054]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ek-OnnTpd9ZL"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "def get_embed(word, current_model):\n",
        "    try:\n",
        "        index = word2index[word]\n",
        "    except :\n",
        "        index = word2index['<UNK>'] #unknown\n",
        "    word = torch.LongTensor([index])\n",
        "    \n",
        "    embed =  (current_model.embedding_center_word(word)+current_model.embedding_outside_word (word))/2\n",
        "    return np.array(embed[0].detach().numpy())\n",
        "\n",
        "embedding_size = 2\n",
        "current_model = Skipgram(voc_size, embedding_size)\n",
        "current_model.load_state_dict(torch.load('/content/Skipgrams_1000.pth'))\n",
        "current_model.eval()\n",
        "\n",
        "test_list = [test_comparative, test_nationality]\n",
        "test_list_name = ['test_comparative', 'test_nationality']\n",
        "\n",
        "results = []\n",
        "for idx in range(20): # We test with only fix 10 samples\n",
        "    emb_x1 = get_embed(input_x1[idx], current_model)\n",
        "    emb_x2 = get_embed(input_x2[idx], current_model)\n",
        "    yhat = stats.spearmanr(emb_x1, emb_x2)\n",
        "    yhat = yhat[0]\n",
        "    #print(yhat)\n",
        "    results.append(yhat)\n"
      ],
      "metadata": {
        "id": "k_LB8ktzddr-"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaUfTwIvcVlY",
        "outputId": "40befeb0-ca8b-4f99-bf9d-232d3415a972"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, -0.9999999999999999, 0.9999999999999999]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "def get_embed(word, current_model):\n",
        "    try:\n",
        "        index = word2index[word]\n",
        "    except :\n",
        "        index = word2index['<UNK>'] #unknown\n",
        "    word = torch.LongTensor([index])\n",
        "    \n",
        "    embed =  (current_model.embedding_center_word(word)+current_model.embedding_outside_word (word))/2\n",
        "    return np.array(embed[0].detach().numpy())\n",
        "\n",
        "embedding_size = 100\n",
        "current_model = Cbow(voc_size, embedding_size)\n",
        "current_model.load_state_dict(torch.load('/content/CBow_model_500.pth'))\n",
        "current_model.eval()\n",
        "\n",
        "test_list = [test_comparative, test_nationality]\n",
        "test_list_name = ['test_comparative', 'test_nationality']\n",
        "\n",
        "results = []\n",
        "for idx in range(20): # We test with only fix 10 samples\n",
        "    emb_x1 = get_embed(input_x1[idx], current_model)\n",
        "    emb_x2 = get_embed(input_x2[idx], current_model)\n",
        "    yhat = stats.spearmanr(emb_x1, emb_x2)\n",
        "    yhat = yhat[0]\n",
        "    #print(yhat)\n",
        "    results.append(yhat)"
      ],
      "metadata": {
        "id": "1nIGEPayerTF"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fb81acuBe5oV",
        "outputId": "69ff290f-50c1-4ece-9f02-3311b27d360d"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9999999999999999, 0.9999999999999999, -0.017701770177017698, -0.017701770177017698, 0.13186918691869187, -0.0207020702070207, 0.9999999999999999, 0.9999999999999999, 0.06977497749774977, 0.06483048304830481, 0.1585238523852385, 0.9999999999999999, -0.05359735973597359, -0.007176717671767176, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.12124812481248125, 0.09236123612361234]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "def get_embed(word, current_model):\n",
        "    try:\n",
        "        index = word2index[word]\n",
        "    except :\n",
        "        index = word2index['<UNK>'] #unknown\n",
        "    word = torch.LongTensor([index])\n",
        "    \n",
        "    embed =  (current_model.embedding_center_word(word)+current_model.embedding_outside_word (word))/2\n",
        "    return np.array(embed[0].detach().numpy())\n",
        "\n",
        "embedding_size = 100\n",
        "current_model = SkipgramNegSampling(voc_size, embedding_size)\n",
        "current_model.load_state_dict(torch.load('/content/Neg_Skipgrams_1000.pth'))\n",
        "current_model.eval()\n",
        "\n",
        "test_list = [test_comparative, test_nationality]\n",
        "test_list_name = ['test_comparative', 'test_nationality']\n",
        "\n",
        "results = []\n",
        "for idx in range(20): # We test with only fix 10 samples\n",
        "    emb_x1 = get_embed(input_x1[idx], current_model)\n",
        "    emb_x2 = get_embed(input_x2[idx], current_model)\n",
        "    yhat = stats.spearmanr(emb_x1, emb_x2)\n",
        "    yhat = yhat[0]\n",
        "    #print(yhat)\n",
        "    results.append(yhat)"
      ],
      "metadata": {
        "id": "DNrWUnECe9iQ"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3nJay5vfOLA",
        "outputId": "9d220588-9bcb-4f45-9682-fd6d955d7929"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9999999999999999, 0.9999999999999999, 0.1318211821182118, 0.1318211821182118, -0.02181818181818182, 0.22720672067206718, 0.9999999999999999, 0.9999999999999999, 0.1029222922292229, 0.14184218421842185, 0.08710471047104709, 0.9999999999999999, 0.014665466546654665, -0.009876987698769876, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.00021602160216021597, 0.10432643264326431]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing with pretrained model**"
      ],
      "metadata": {
        "id": "1ELoqFOzfUyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "glove_file = datapath('/root/projects/NLP/Assignment/19_Jan_Glove/glove.6B.100d.txt')\n",
        "model = KeyedVectors.load_word2vec_format(glove_file, binary=False, no_header=True)"
      ],
      "metadata": {
        "id": "ajjM5YRofQSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = list()\n",
        "for i in range(10):\n",
        "    emb_x1 = model[input_x1[i]]\n",
        "    emb_x2 = model[input_x2[i]]\n",
        "    result = stats.spearmanr(emb_x1, emb_x2)\n",
        "    result = result[0]\n",
        "    yhat.append(result)"
      ],
      "metadata": {
        "id": "Lkzw_GurfjVO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}