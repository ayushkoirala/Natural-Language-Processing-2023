{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fU-YTqj4dMqp"
      },
      "source": [
        "**Submitted by:** \n",
        "          \n",
        "          Name: Ayush Koirala\n",
        "          id : st122802\n",
        "\n",
        "**Assignment on Glove **\n",
        "\n",
        "Constraint: Only use our code (not other code....)\n",
        "\n",
        "1. I guess you already try a bigger corpus\n",
        "2. I guess you already try window size 2\n",
        "3. I guess you already have skipgram, skipgram(neg), cbow, glove\n",
        "\n",
        "Do this:\n",
        "1. Compare them based on syntactic accuracy and semantic accuracy, similar to how is done in https://nlp.stanford.edu/pubs/glove.pdf (see Table 2) - NO NEED to try 1000 or 300 embed size.....I just want you to learn how to do experiment.....\n",
        "2. Try to find a correlation with just ONE similarity dataset (which humans judge how similar is two words.....)\n",
        "\n",
        "Point criteria:\n",
        "0:  Not done\n",
        "1: ok\n",
        "2: with comments / explanation / figures.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sf4p7uR_eEc4"
      },
      "source": [
        "**Importing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iWJsrHp2SF4t"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoCXdK78eMaL"
      },
      "source": [
        "**ETL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTq9VskQSJ8_",
        "outputId": "42f871db-1e88-48bd-807b-7358b387e1f2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk \n",
        "from nltk.corpus import brown\n",
        "nltk.download('brown')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfGHKOS6S3Ly",
        "outputId": "12963ce0-fa39-4387-eb18-3117159a412c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['the', 'fulton', 'county', 'grand', 'jury', 'said', 'friday', 'an', 'investigation', 'of', \"atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['the', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'city', 'executive', 'committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'city', 'of', 'atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ['the', 'september-october', 'term', 'jury', 'had', 'been', 'charged', 'by', 'fulton', 'superior', 'court', 'judge', 'durwood', 'pye', 'to', 'investigate', 'reports', 'of', 'possible', '``', 'irregularities', \"''\", 'in', 'the', 'hard-fought', 'primary', 'which', 'was', 'won', 'by', 'mayor-nominate', 'ivan', 'allen', 'jr.', '.'], ['``', 'only', 'a', 'relative', 'handful', 'of', 'such', 'reports', 'was', 'received', \"''\", ',', 'the', 'jury', 'said', ',', '``', 'considering', 'the', 'widespread', 'interest', 'in', 'the', 'election', ',', 'the', 'number', 'of', 'voters', 'and', 'the', 'size', 'of', 'this', 'city', \"''\", '.'], ['the', 'jury', 'said', 'it', 'did', 'find', 'that', 'many', 'of', \"georgia's\", 'registration', 'and', 'election', 'laws', '``', 'are', 'outmoded', 'or', 'inadequate', 'and', 'often', 'ambiguous', \"''\", '.']]\n"
          ]
        }
      ],
      "source": [
        "corpus = brown.sents()[:1000]\n",
        "#Transforming to lower case\n",
        "corpus = [[word.lower() for word in sent] for sent in corpus] # Cool list comprehension trick!\n",
        "print(corpus[0:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbwPt8rAeyII",
        "outputId": "6c4e5c30-7c30-4565-8d72-ca6e08574ba7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1000\n"
          ]
        }
      ],
      "source": [
        "print(len(corpus))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24IjmIk4e7Fk"
      },
      "source": [
        "**Doing flatten and Get word sequences and unique words**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SXA4kPhSQ_-",
        "outputId": "00e57710-032e-4c10-b8bb-73025aa557e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['caldwell', 'list', 'after', 'tea', 'twelve']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Doing flatten and Get word sequences and unique words\n",
        "flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "vocab = list(set(flatten(corpus)))\n",
        "vocab[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AptY9PJ_Tv6u",
        "outputId": "c98b5874-b33a-46b1-c696-12c3289b2c2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4272"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcDoWnate9bw"
      },
      "source": [
        "**Numericalize**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OJK6q5KUNMz",
        "outputId": "0ca3808f-52f5-4239-e446-07936fe9250e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'caldwell': 0, 'list': 1, 'after': 2, 'tea': 3, 'twelve': 4}\n"
          ]
        }
      ],
      "source": [
        "import itertools\n",
        "\n",
        "word2index = {w: i for i, w in enumerate(vocab)}\n",
        "index2word = {v:k for k, v in word2index.items()}\n",
        "\n",
        "out = dict(itertools.islice(word2index.items(), 5))\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RMU7d_HrUWUe"
      },
      "outputs": [],
      "source": [
        "vocab.append('<UNK>')\n",
        "word2index['<UNK>'] = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsCxwVW1f8ii"
      },
      "source": [
        "**Glove Method**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtgmYi46U8z4",
        "outputId": "4eee8afc-079d-4ba5-e40d-62820bda6428"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'the': 1569, 'fulton': 14, 'county': 35, 'grand': 7, 'jury': 23}\n"
          ]
        }
      ],
      "source": [
        "#2. Build Co-occurence Matrix X and displaying only first 5\n",
        "from collections import Counter\n",
        "\n",
        "X_i = Counter(flatten(corpus)) # X_i\n",
        "out = dict(itertools.islice(X_i.items(), 5))\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0c_5ZhjbVWRA"
      },
      "outputs": [],
      "source": [
        "#modifing previous assignment random batch\n",
        "def random_batch_skipgram(corpus,window_size=1):\n",
        "    skip_grams = []\n",
        "    for sent in corpus:\n",
        "        for i in range(1, len(sent) - 1):  # we should start  from 1 because 0 has no context\n",
        "            target = sent[i]\n",
        "            context = []\n",
        "            for j in range(window_size):\n",
        "                if i - (j + 1) >= 0:  ## Checking  if anything fall outside of range from the left of list\n",
        "                     context.append(sent[i - (j + 1)])\n",
        "                if i + (j + 1) < len(sent): \n",
        "                     context.append(sent[i + (j + 1)])\n",
        "            for w in context:\n",
        "                skip_grams.append((target,w))\n",
        "    return skip_grams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1xefCoSjiVo"
      },
      "source": [
        "**Find co-occurance in skip_grams with window of 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcdo5XUIW7DB",
        "outputId": "c50d9bf6-0963-471b-cba8-da4aca0d9375"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{('fulton', 'the'): 7, ('fulton', 'county'): 6, ('fulton', 'grand'): 1, ('county', 'fulton'): 6, ('county', 'grand'): 1}\n"
          ]
        }
      ],
      "source": [
        "X_ik_skipgram = Counter(random_batch_skipgram(corpus,window_size=2))\n",
        "\n",
        "out = dict(itertools.islice(X_ik_skipgram.items(), 5))\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IofKlBaGplL9"
      },
      "source": [
        "**Weight function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HF1IxQhJXoBW"
      },
      "outputs": [],
      "source": [
        "#simply a normalized function...don't worry too much\n",
        "def weighting(w_i, w_j, X_ik):\n",
        "        \n",
        "    #check whether the co-occurrences exist between these two words\n",
        "    try:\n",
        "        x_ij = X_ik[(w_i, w_j)]\n",
        "    except:\n",
        "        x_ij = 1  #if does not exist, set it to 1\n",
        "                \n",
        "    x_max = 100 #100 # fixed in paper  #cannot exceed 100 counts\n",
        "    alpha = 0.75\n",
        "    \n",
        "    #if co-occurrence does not exceed 100, scale it based on some alpha\n",
        "    if x_ij < x_max:\n",
        "        result = (x_ij/x_max)**alpha  #scale it\n",
        "    else:\n",
        "        result = 1  #if is greater than max, set it to 1 maximum\n",
        "    \n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I97fp6RzXupq",
        "outputId": "ae8f1eb8-ccc3-4233-866f-ddd146c7974a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "9131401it [00:28, 321349.78it/s]\n",
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#from itertools import combinations_with_replacement\n",
        "from itertools import combinations_with_replacement\n",
        "from tqdm import tqdm\n",
        "\n",
        "X_ik = {}  #for keeping the co-occurences\n",
        "weighting_dic = {} #scaling the percentage of sampling\n",
        "\n",
        "for bigram in tqdm(combinations_with_replacement(vocab, 2)):\n",
        "    if X_ik_skipgram.get(bigram) is not None:  #matches \n",
        "        co_occer = X_ik_skipgram[bigram]  #get the count from what we already counted\n",
        "        X_ik[bigram] = co_occer + 1 # + 1 for stability issue\n",
        "        X_ik[(bigram[1],bigram[0])] = co_occer+1   #count also for the opposite\n",
        "    else:\n",
        "        pass\n",
        "        \n",
        "    weighting_dic[bigram] = weighting(bigram[0], bigram[1], X_ik)\n",
        "    weighting_dic[(bigram[1], bigram[0])] = weighting(bigram[1], bigram[0], X_ik)\n",
        "\n",
        "print(f\"{X_ik=}\")\n",
        "print(f\"{weighting_dic=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-N87EfKjX8ho"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def random_batch(batch_size, word_sequence, skip_grams, X_ik, weighting_dic):\n",
        "    \n",
        "    #convert to id since our skip_grams is word, not yet id\n",
        "    skip_grams_id = [(word2index[skip_gram[0]], word2index[skip_gram[1]]) for skip_gram in skip_grams]\n",
        "    \n",
        "    random_inputs = []\n",
        "    random_labels = []\n",
        "    random_coocs  = []\n",
        "    random_weightings = []\n",
        "    random_index = np.random.choice(range(len(skip_grams_id)), batch_size, replace=False) #randomly pick without replacement\n",
        "        \n",
        "    for i in random_index:\n",
        "        random_inputs.append([skip_grams_id[i][0]])  # target, e.g., 2\n",
        "        random_labels.append([skip_grams_id[i][1]])  # context word, e.g., 3\n",
        "        \n",
        "        #get cooc\n",
        "        pair = skip_grams[i]\n",
        "        try:\n",
        "            cooc = X_ik[pair]\n",
        "        except:\n",
        "            cooc = 1\n",
        "        random_coocs.append([math.log(cooc)])\n",
        "        \n",
        "        #get weighting\n",
        "        weighting = weighting_dic[pair]\n",
        "        random_weightings.append([weighting])\n",
        "                    \n",
        "    return np.array(random_inputs), np.array(random_labels), np.array(random_coocs), np.array(random_weightings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1PgfyVwZ86b",
        "outputId": "9589519a-efb3-4aed-bb8f-bfa0744a3c46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input:  [[1543]\n",
            " [3056]]\n",
            "Target:  [[1079]\n",
            " [4058]]\n",
            "Cooc:  [[1.09861229]\n",
            " [0.69314718]]\n",
            "Weighting:  [[0.07208434]\n",
            " [0.05318296]]\n"
          ]
        }
      ],
      "source": [
        "#testing the method\n",
        "batch_size = 2 # mini-batch size\n",
        "skip_grams = random_batch_skipgram(corpus,window_size=2)\n",
        "input_batch, target_batch, cooc_batch, weighting_batch = random_batch(batch_size, corpus, skip_grams, X_ik, weighting_dic)\n",
        "\n",
        "print(\"Input: \", input_batch)\n",
        "print(\"Target: \", target_batch)\n",
        "print(\"Cooc: \", cooc_batch)\n",
        "print(\"Weighting: \", weighting_batch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "yVD_Gpy3Z_cF"
      },
      "outputs": [],
      "source": [
        "class GloVe(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size,embed_size):\n",
        "        super(GloVe,self).__init__()\n",
        "        self.embedding_v = nn.Embedding(vocab_size, embed_size) # center embedding\n",
        "        self.embedding_u = nn.Embedding(vocab_size, embed_size) # out embedding\n",
        "        \n",
        "        self.v_bias = nn.Embedding(vocab_size, 1)\n",
        "        self.u_bias = nn.Embedding(vocab_size, 1)\n",
        "        \n",
        "    def forward(self, center_words, target_words, coocs, weighting):\n",
        "        center_embeds = self.embedding_v(center_words) # [batch_size, 1, emb_size]\n",
        "        target_embeds = self.embedding_u(target_words) # [batch_size, 1, emb_size]\n",
        "        \n",
        "        center_bias = self.v_bias(center_words).squeeze(1)\n",
        "        target_bias = self.u_bias(target_words).squeeze(1)\n",
        "        \n",
        "        inner_product = target_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2)\n",
        "        #[batch_size, 1, emb_size] @ [batch_size, emb_size, 1] = [batch_size, 1, 1] = [batch_size, 1]\n",
        "        \n",
        "        #note that coocs already got log\n",
        "        loss = weighting*torch.pow(inner_product +center_bias + target_bias - coocs, 2)\n",
        "        \n",
        "        return torch.sum(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ha4jqnRstNSf"
      },
      "source": [
        "**Glove Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5np6gz6tSKc",
        "outputId": "28d4c47e-0b4b-4bb2-d339-fdd3cd1de8e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# Trying to use Colab\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8mskB2Ct6tx"
      },
      "outputs": [],
      "source": [
        "voc_size = len(vocab)\n",
        "batch_size     = 10 # mini-batch size\n",
        "embedding_size = 100 #so we can later plot\n",
        "model          = GloVe(voc_size, embedding_size)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNUrZa-IuNsN"
      },
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOferOn7aYis",
        "outputId": "3c47785c-c5fe-4dc8-d149-8b91c0c9ef96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1000 | cost: 115.496872 | time: 0m 0s\n",
            "Epoch: 2000 | cost: 98.368538 | time: 0m 0s\n",
            "Epoch: 3000 | cost: 80.760368 | time: 0m 0s\n",
            "Epoch: 4000 | cost: 24.985233 | time: 0m 0s\n",
            "Epoch: 5000 | cost: 24.683460 | time: 0m 0s\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# Training\n",
        "num_epochs = 5000\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    start = time.time()\n",
        "    \n",
        "    input_batch, target_batch, cooc_batch, weighting_batch = random_batch(batch_size, corpus, skip_grams, X_ik, weighting_dic)\n",
        "    input_batch  = torch.LongTensor(input_batch).to(device)          #[batch_size, 1]\n",
        "    target_batch = torch.LongTensor(target_batch).to(device)          #[batch_size, 1]\n",
        "    cooc_batch   = torch.FloatTensor(cooc_batch).to(device)           #[batch_size, 1]\n",
        "    weighting_batch = torch.FloatTensor(weighting_batch).to(device)   #[batch_size, 1]\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss = model(input_batch, target_batch, cooc_batch, weighting_batch)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    end = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start, end)\n",
        "\n",
        "    if (epoch + 1) % 1000 == 0:\n",
        "        print(f\"Epoch: {epoch + 1} | cost: {loss:.6f} | time: {epoch_mins}m {epoch_secs}s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKdAJuEdaZAS"
      },
      "outputs": [],
      "source": [
        "# Save model\n",
        "path = '/content/Glove_5000.pth'\n",
        "torch.save(model.state_dict(), path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lf4faztJvii7"
      },
      "source": [
        "**Now Trying for SkipGram**\n",
        "\n",
        "Taking everything from 1st assigment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "8a-6LyXlvh66"
      },
      "outputs": [],
      "source": [
        "def random_batch(batch_size, word_sequence, window_size=1):\n",
        "    skip_grams = []\n",
        "    for sent in corpus:\n",
        "        for i in range(1, len(sent) - 1):\n",
        "            target = word2index[sent[i]]\n",
        "            context = []\n",
        "            for j in range(window_size):\n",
        "                if i - (j + 1) >= 0: \n",
        "                    context.append(word2index[sent[i - (j + 1)]])\n",
        "                \n",
        "                if i + (j + 1) < len(sent): \n",
        "                    context.append(word2index[sent[i + (j + 1)]])\n",
        "            for w in context:\n",
        "                skip_grams.append([target, w])\n",
        "    \n",
        "    random_inputs = []\n",
        "    random_labels = []\n",
        "    random_index = np.random.choice(range(len(skip_grams)), batch_size, replace=False) \n",
        "    for i in random_index:\n",
        "        random_inputs.append([skip_grams[i][0]])  \n",
        "        random_labels.append([skip_grams[i][1]])  \n",
        "            \n",
        "    return np.array(random_inputs), np.array(random_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOA7pXSgvh_h",
        "outputId": "8c7e3e92-6400-47f2-ad88-7a528712df86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input:  [[2203]\n",
            " [1079]]\n",
            "Target:  [[4097]\n",
            " [4020]]\n"
          ]
        }
      ],
      "source": [
        "#testing\n",
        "batch_size =2 \n",
        "window_size = 2\n",
        "\n",
        "input_batch, target_batch = random_batch(batch_size, corpus, window_size)\n",
        "\n",
        "print(\"Input: \", input_batch)\n",
        "print(\"Target: \", target_batch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "ivhrR5Uda65G"
      },
      "outputs": [],
      "source": [
        "class Skipgram(nn.Module):\n",
        "    \n",
        "    def __init__(self, voc_size, emb_size):\n",
        "        super(Skipgram, self).__init__()\n",
        "        self.embedding_center_word  = nn.Embedding(voc_size, emb_size)  #is a lookup table mapping all ids in voc_size, into some vector of size emb_size\n",
        "        self.embedding_outside_word = nn.Embedding(voc_size, emb_size)\n",
        "    \n",
        "    def forward(self, center_word, outside_word, all_vocabs):\n",
        "        #center_word, outside_word: (batch_size, 1)\n",
        "        #all_vocabs: (batch_size, voc_size)\n",
        "        \n",
        "        #convert them into embedding\n",
        "        center_word_embed  = self.embedding_center_word(center_word)     #(batch_size, 1, emb_size)\n",
        "        outside_word_embed = self.embedding_outside_word(outside_word)   #(batch_size, 1, emb_size)\n",
        "        all_vocabs_embed   = self.embedding_outside_word(all_vocabs)     #(batch_size, voc_size, emb_size)\n",
        "        \n",
        "        #bmm is basically @ or .dot , but across batches (i.e., ignore the batch dimension)\n",
        "        top_term = outside_word_embed.bmm(center_word_embed.transpose(1, 2)).squeeze(2)\n",
        "        #(batch_size, 1, emb_size) @ (batch_size, emb_size, 1) = (batch_size, 1, 1) ===> (batch_size, 1)\n",
        "        \n",
        "        top_term_exp = torch.exp(top_term)  #exp(uo vc)\n",
        "        #(batch_size, 1)\n",
        "        \n",
        "        lower_term = all_vocabs_embed.bmm(center_word_embed.transpose(1, 2)).squeeze(2)\n",
        "         #(batch_size, voc_size, emb_size) @ (batch_size, emb_size, 1) = (batch_size, voc_size, 1) = (batch_size, voc_size)\n",
        "         \n",
        "        lower_term_sum = torch.sum(torch.exp(lower_term), 1) #sum exp(uw vc)\n",
        "        #(batch_size, 1)\n",
        "        \n",
        "        loss_fn = -torch.mean(torch.log(top_term_exp / lower_term_sum))\n",
        "        #(batch_size, 1) / (batch_size, 1) ==mean==> scalar\n",
        "        \n",
        "        return loss_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JydLY5qBwoiy",
        "outputId": "a4cd40b1-7b2c-48b7-8790-bf8cfca9421f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4273"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "voc_size = len(vocab)\n",
        "voc_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOkmxvtjwsa7",
        "outputId": "88b16d62-74b2-4f8c-8352-d25b95c894f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10, 4273])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size = 10\n",
        "\n",
        "def prepare_sequence(seq, word2index):\n",
        "    #map(function, list of something)\n",
        "    #map will look at each of element in this list, and apply this function\n",
        "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
        "    return torch.LongTensor(idxs)\n",
        "\n",
        "all_vocabs = prepare_sequence(list(vocab), word2index).expand(batch_size, voc_size)\n",
        "all_vocabs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "2YEXpTJJwvZ8"
      },
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-p_wDgNJw0kJ",
        "outputId": "74f79c2b-64ca-4bb3-f7e5-a83953136d4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 100 | cost: 9.959069 | time: 0m 15s\n",
            "Epoch: 200 | cost: 11.423738 | time: 0m 30s\n",
            "Epoch: 300 | cost: 9.541531 | time: 0m 45s\n",
            "Epoch: 400 | cost: 8.458012 | time: 1m 0s\n",
            "Epoch: 500 | cost: 8.943056 | time: 1m 15s\n",
            "Epoch: 600 | cost: 8.225544 | time: 1m 31s\n",
            "Epoch: 700 | cost: 8.510216 | time: 1m 46s\n",
            "Epoch: 800 | cost: 7.950565 | time: 2m 1s\n",
            "Epoch: 900 | cost: 8.315861 | time: 2m 16s\n",
            "Epoch: 1000 | cost: 9.020043 | time: 2m 31s\n"
          ]
        }
      ],
      "source": [
        "batch_size     = 10 # mini-batch size\n",
        "embedding_size = 2 #so we can later plot\n",
        "window_size=2\n",
        "model  = Skipgram(voc_size, embedding_size)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "import time\n",
        "\n",
        "# Training\n",
        "start_train_time = time.time()\n",
        "num_epochs = 1000\n",
        "start = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    input_batch, target_batch = random_batch(batch_size, corpus, window_size)\n",
        "    input_batch  = torch.LongTensor(input_batch) #[batch_size, 1]\n",
        "    target_batch = torch.LongTensor(target_batch) #[batch_size, 1]\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss = model(input_batch, target_batch, all_vocabs)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        end = time.time()\n",
        "        epoch_mins, epoch_secs = epoch_time(start, end)\n",
        "        print(f\"Epoch: {epoch + 1} | cost: {loss:.6f} | time: {epoch_mins}m {epoch_secs}s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "FHQ6O4b3xGRY",
        "outputId": "41df080a-94ea-4756-cc32-0cc9957071ba"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "def get_embed(word):\n",
        "    id_tensor = torch.LongTensor([word2index[word]])\n",
        "    v_embed = model.embedding_center_word(id_tensor)\n",
        "    u_embed = model.embedding_outside_word(id_tensor) \n",
        "    word_embed = (v_embed + u_embed) / 2 \n",
        "    x, y = word_embed[0][0].item(), word_embed[0][1].item()\n",
        "\n",
        "    return x, y\n",
        "\n",
        "plt.figure(figsize=(6,3))\n",
        "for i, word in enumerate(vocab[:20]): #loop each unique vocab\n",
        "    x, y = get_embed(word)\n",
        "    plt.scatter(x, y)\n",
        "    plt.annotate(word, xy=(x, y), xytext=(5, 2), textcoords='offset points')\n",
        "plt.title('Window size of 2')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAljsP2-0GPT"
      },
      "outputs": [],
      "source": [
        "# Save model\n",
        "path = '/content/Skipgrams_1000.pth'\n",
        "torch.save(model.state_dict(), path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZlH2kSD0S6J"
      },
      "source": [
        "**CBOW**\n",
        "\n",
        "Copying everything from 1st assignment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "U5XZMiTY0ViM"
      },
      "outputs": [],
      "source": [
        "# Random batch for cbow\n",
        "\n",
        "# Random batch for cbow\n",
        "\n",
        "def random_batch_cbow(batch_size, word_sequence, window_size=1):\n",
        "\n",
        "    cbow = []\n",
        "\n",
        "    for sent in corpus:\n",
        "        for i in range(1, len(sent) - 1): # So we can modify the window size\n",
        "            target = word2index[sent[i]]\n",
        "            context = list()\n",
        "            \n",
        "            for j in range(window_size):\n",
        "                \n",
        "                if i - (j + 1) >= 0: # Check if it outside of range from the left of list\n",
        "                    context.append(word2index[sent[i - (j + 1)]])\n",
        "                \n",
        "                if i + (j + 1) < len(sent): # Check if it outside of range from the right of list\n",
        "                    context.append(word2index[sent[i + (j + 1)]])\n",
        "            \n",
        "            # This part is different from skipgram\n",
        "            # Now we use all context as input and target as label\n",
        "            for w in context:\n",
        "                cbow.append([context, target])\n",
        "    \n",
        "    random_inputs = []\n",
        "    random_labels = []\n",
        "    random_index = np.random.choice(range(len(cbow)), batch_size, replace=False) #randomly pick without replacement\n",
        "    \n",
        "    for i in random_index:\n",
        "        random_inputs.append(cbow[i][0])  # Context word that we want as input\n",
        "        random_labels.append([cbow[i][1]])  # Target word that we want as label\n",
        "    \n",
        "    return np.array(random_inputs), np.array(random_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaxpIZt20tAE",
        "outputId": "0971722b-7593-42db-a014-8a24520c7fb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input:  [[1419 3637 2021 1033]\n",
            " [1085 1263 3734 2114]]\n",
            "Target:  [[3830]\n",
            " [1021]]\n"
          ]
        }
      ],
      "source": [
        " # mini-batch size\n",
        "batch_size = 2\n",
        "input_batch, target_batch = random_batch_cbow(batch_size, corpus, 2)\n",
        "\n",
        "print(\"Input: \", input_batch)\n",
        "print(\"Target: \", target_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "9VzxPbtE0xMz"
      },
      "outputs": [],
      "source": [
        "class Cbow(nn.Module):\n",
        "    \n",
        "    def __init__(self, voc_size, emb_size):\n",
        "        super(Cbow, self).__init__()\n",
        "        self.embedding_center_word  = nn.Embedding(voc_size, emb_size)  #is a lookup table mapping all ids in voc_size, into some vector of size emb_size\n",
        "        self.embedding_outside_word = nn.Embedding(voc_size, emb_size)\n",
        "    \n",
        "    def forward(self, center_word, outside_word, all_vocabs):\n",
        "        \n",
        "        #convert them into embedding\n",
        "        center_word_embed  = self.embedding_center_word(center_word)     #(batch_size, 1, emb_size)\n",
        "        outside_word_embed = self.embedding_outside_word(outside_word)   #(batch_size, 1, emb_size)\n",
        "        all_vocabs_embed   = self.embedding_outside_word(all_vocabs)     #(batch_size, voc_size, emb_size)\n",
        "        \n",
        "        #bmm is basically @ or .dot , but across batches (i.e., ignore the batch dimension)\n",
        "        top_term = outside_word_embed.bmm(center_word_embed.transpose(1, 2)).squeeze(2)\n",
        "        #(batch_size, 1, emb_size) @ (batch_size, emb_size, 1) = (batch_size, 1, 1) ===> (batch_size, 1)\n",
        "        \n",
        "        top_term_exp = torch.exp(top_term)  #exp(uo vc)\n",
        "        #(batch_size, 1)\n",
        "        \n",
        "        lower_term = all_vocabs_embed.bmm(center_word_embed.transpose(1, 2)).squeeze(2)\n",
        "         #(batch_size, voc_size, emb_size) @ (batch_size, emb_size, 1) = (batch_size, voc_size, 1) = (batch_size, voc_size)\n",
        "         \n",
        "        lower_term_sum = torch.sum(torch.exp(lower_term), 1) #sum exp(uw vc)\n",
        "        #(batch_size, 1)\n",
        "        \n",
        "        loss_fn = -torch.mean(torch.log(top_term_exp / lower_term_sum))\n",
        "        #(batch_size, 1) / (batch_size, 1) ==mean==> scalar\n",
        "        \n",
        "        return loss_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "_PDnq6gM2AEb"
      },
      "outputs": [],
      "source": [
        "batch_size     = 10 # mini-batch size\n",
        "embedding_size = 100 #so we can later plot\n",
        "model = Cbow(voc_size, embedding_size)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "all_vocabs = all_vocabs.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUcKQvFm2Go6",
        "outputId": "6569e78b-0bc7-4f11-8b22-1103ff6c7fd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 100 | cost: 34.562569 | time: 0m 11s\n",
            "Epoch: 200 | cost: 24.776230 | time: 0m 10s\n",
            "Epoch: 300 | cost: 32.017139 | time: 0m 10s\n",
            "Epoch: 400 | cost: 30.892143 | time: 0m 14s\n",
            "Epoch: 500 | cost: 29.277050 | time: 0m 13s\n"
          ]
        }
      ],
      "source": [
        "# Training\n",
        "import time\n",
        "num_epochs = 500\n",
        "start = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    input_batch, target_batch = random_batch_cbow(batch_size, corpus, 1)\n",
        "    input_batch  = torch.LongTensor(input_batch).to(device)  #[batch_size, 1]\n",
        "    target_batch = torch.LongTensor(target_batch).to(device) #[batch_size, 1]\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss = model(input_batch, target_batch, all_vocabs)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        end = time.time()\n",
        "        epoch_mins, epoch_secs = epoch_time(start, end)\n",
        "        print(f\"Epoch: {epoch + 1} | cost: {loss:.6f} | time: {epoch_mins}m {epoch_secs}s\")\n",
        "        start = time.time()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "242Nr-m75IOe"
      },
      "source": [
        "**Saving Model**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "PasTsmUr2UGY"
      },
      "outputs": [],
      "source": [
        "# Save model\n",
        "path = '/content/CBow_model_500.pth'\n",
        "torch.save(model.state_dict(), path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqX4eT1LNVAk"
      },
      "source": [
        "**Negative Sampling**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Ha6W_TI55Pb4"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "word_count = Counter(flatten(corpus))\n",
        "num_total_words = sum([c for w, c in word_count.items()])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "G8Xa8rq1NbZM"
      },
      "outputs": [],
      "source": [
        "# Create unigram table\n",
        "Z = 0.001\n",
        "unigram_table = []\n",
        "\n",
        "for vo in vocab:\n",
        "    unigram_table.extend([vo] * int(((word_count[vo]/num_total_words)**0.75)/Z))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "hOLGYmwmNd0q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "qNdiLaJVN1XI"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def prepare_sequence(seq, word2index):\n",
        "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
        "    return torch.LongTensor(idxs)\n",
        "\n",
        "def negative_sampling(targets, unigram_table, k):\n",
        "    batch_size = targets.size(0)\n",
        "    neg_samples = []\n",
        "    for i in range(batch_size):\n",
        "        nsample = []\n",
        "        target_index = targets[i].item()\n",
        "        while len(nsample) < k: # num of sampling\n",
        "            neg = random.choice(unigram_table)\n",
        "            if word2index[neg] == target_index:\n",
        "                continue\n",
        "            nsample.append(neg)\n",
        "        neg_samples.append(prepare_sequence(nsample, word2index).view(1, -1))\n",
        "    \n",
        "    return torch.cat(neg_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "6saXwIygOKwE"
      },
      "outputs": [],
      "source": [
        "class SkipgramNegSampling(nn.Module):\n",
        "    \n",
        "    def __init__(self, voc_size, emb_size):\n",
        "        super(SkipgramNegSampling, self).__init__()\n",
        "        self.embedding_center_word  = nn.Embedding(voc_size, emb_size)\n",
        "        self.embedding_outside_word = nn.Embedding(voc_size, emb_size)\n",
        "        self.logsigmoid = nn.LogSigmoid()\n",
        "        \n",
        "    def forward(self, center_words, outside_words, negative_words):\n",
        "        #center_words, outside_words: (batch_size, 1)\n",
        "        #negative_words:  (batch_size, k)\n",
        "        \n",
        "        center_embed  = self.embedding_center_word(center_words)    #(batch_size, 1, emb_size)\n",
        "        outside_embed = self.embedding_outside_word(outside_words)  #(batch_size, 1, emb_size)\n",
        "        neg_embed     = self.embedding_outside_word(negative_words) #(batch_size, k, emb_size)\n",
        "        \n",
        "        uovc          =  outside_embed.bmm(center_embed.transpose(1, 2)).squeeze(2)  #(batch_size, 1)\n",
        "        ukvc          = -neg_embed.bmm(center_embed.transpose(1, 2)).squeeze(2)  #(batch_size, k)\n",
        "        ukvc_sum      =  torch.sum(ukvc, 1).view(-1, 1) #(batch_size, 1)\n",
        "        \n",
        "        loss = self.logsigmoid(uovc) + self.logsigmoid(ukvc_sum)  #(batch_size, 1) + (batch_size, 1)\n",
        "                \n",
        "        return -torch.mean(loss)  #scalar, loss should be scalar, to call backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "SiY35pDsOR2k"
      },
      "outputs": [],
      "source": [
        "# Initialize parameter\n",
        "batch_size     = 10 # mini-batch size\n",
        "embedding_size = 100 #so we can later plot\n",
        "model          = SkipgramNegSampling(voc_size, embedding_size)\n",
        "num_neg        = 10 # num of negative sampling\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzsRgw_3OVED",
        "outputId": "f8dfabe1-fa4c-4b14-dbd6-c0c8aecb1869"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 100 | cost: 15.262489 | time: 0m 0s\n",
            "Epoch: 200 | cost: 19.257448 | time: 0m 0s\n",
            "Epoch: 300 | cost: 16.329243 | time: 0m 0s\n",
            "Epoch: 400 | cost: 9.641607 | time: 0m 0s\n",
            "Epoch: 500 | cost: 16.024637 | time: 0m 0s\n",
            "Epoch: 600 | cost: 9.736855 | time: 0m 0s\n",
            "Epoch: 700 | cost: 11.180909 | time: 0m 0s\n",
            "Epoch: 800 | cost: 32.525230 | time: 0m 0s\n",
            "Epoch: 900 | cost: 14.299477 | time: 0m 0s\n",
            "Epoch: 1000 | cost: 21.399591 | time: 0m 0s\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_train_time = time.time()\n",
        "\n",
        "# Training\n",
        "num_epochs = 1000\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    start = time.time()\n",
        "    \n",
        "    input_batch, target_batch = random_batch(batch_size, corpus, 2)\n",
        "    \n",
        "    #input_batch: [batch_size, 1]\n",
        "    input_batch = torch.LongTensor(input_batch)\n",
        "    \n",
        "    #target_batch: [batch_size, 1]\n",
        "    target_batch = torch.LongTensor(target_batch)\n",
        "    \n",
        "    #negs_batch:   [batch_size, num_neg]\n",
        "    negs_batch = negative_sampling(target_batch, unigram_table, num_neg)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "        \n",
        "    loss = model(input_batch, target_batch, negs_batch)\n",
        "    \n",
        "    end = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start, end)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print(f\"Epoch: {epoch + 1} | cost: {loss:.6f} | time: {epoch_mins}m {epoch_secs}s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "_40nQ5_ROm7u"
      },
      "outputs": [],
      "source": [
        "# Save model\n",
        "path = '/content/Neg_Skipgrams_1000.pth'\n",
        "torch.save(model.state_dict(), path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzTAeRsLP4oZ"
      },
      "source": [
        "**Testing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLaJeJ7UPxmz",
        "outputId": "7eeeddda-130c-41ed-d2eb-872cce1c4beb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[': capital-common-countries', 'Athens Greece Baghdad Iraq', 'Athens Greece Bangkok Thailand', 'Athens Greece Beijing China', 'Athens Greece Berlin Germany', 'Athens Greece Bern Switzerland', 'Athens Greece Cairo Egypt', 'Athens Greece Canberra Australia', 'Athens Greece Hanoi Vietnam', 'Athens Greece Havana Cuba']\n"
          ]
        }
      ],
      "source": [
        "# Load the data\n",
        "def read_data(path):\n",
        "    file = open(path, 'r') # Dataset from amamda\n",
        "    contents = file.read()\n",
        "    contents = contents.split('\\n') # Seperate chunk of text into substring\n",
        "    file.close()\n",
        "    return contents\n",
        "\n",
        "path = '/content/questions-words.txt'\n",
        "text = read_data(path)\n",
        "print(text[0:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6Ia3qpTQn4o"
      },
      "source": [
        "**Find the seperator name and index**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGauVngiQYz8",
        "outputId": "d66d407f-90ad-4dc7-ddfb-c47b74eeebd1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0, ': capital-common-countries'),\n",
              " (507, ': capital-world'),\n",
              " (5032, ': currency'),\n",
              " (5899, ': city-in-state'),\n",
              " (8367, ': family'),\n",
              " (8874, ': gram1-adjective-to-adverb'),\n",
              " (9867, ': gram2-opposite'),\n",
              " (10680, ': gram3-comparative'),\n",
              " (12013, ': gram4-superlative'),\n",
              " (13136, ': gram5-present-participle'),\n",
              " (14193, ': gram6-nationality-adjective'),\n",
              " (15793, ': gram7-past-tense'),\n",
              " (17354, ': gram8-plural'),\n",
              " (18687, ': gram9-plural-verbs')]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seperator = [(idx, sent) for idx, sent in enumerate(text) if sent[0] == ':']\n",
        "seperator "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3-7_KwTQq4w",
        "outputId": "65f9c64a-4768-45ec-a64b-0e01aa578127"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bad worse big bigger\n",
            "Ukraine Ukrainian Switzerland Swiss\n"
          ]
        }
      ],
      "source": [
        "# Let's use comparative and nationality-adjective\n",
        "comparative = text[10681:12012]\n",
        "nationality = text[14194:15793]\n",
        "\n",
        "# Concatenate\n",
        "test_text = comparative + nationality\n",
        "\n",
        "# Checking\n",
        "print(test_text[0])\n",
        "print(test_text[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwIv6CkWRUwy",
        "outputId": "2844d1cf-0301-4697-f717-28f2fe366793"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['bad', 'worse', 'big', 'bigger'], ['bad', 'worse', 'bright', 'brighter'], ['bad', 'worse', 'cheap', 'cheaper'], ['bad', 'worse', 'cold', 'colder'], ['bad', 'worse', 'cool', 'cooler']]\n"
          ]
        }
      ],
      "source": [
        "#Now split the words\n",
        "test_comparative = [sent.split(\" \") for sent in comparative]\n",
        "test_nationality = [sent.split(\" \") for sent in nationality]\n",
        "test_corpus = [sent.split(\" \") for sent in test_text]\n",
        "print(test_corpus[0:5])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGPHZkLKR9id"
      },
      "source": [
        "**Flatten and get Unique words**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOFjsH00RzUk",
        "outputId": "65b5e3ef-26f7-4975-f455-efb32f08828c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Icelandic', 'Moldova', 'Chile', 'stronger', 'Brazil']"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "test_vocab = list(set(flatten(test_corpus)))\n",
        "test_vocab[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "urlO-GYXR7lH"
      },
      "outputs": [],
      "source": [
        "test_word2index = dict()\n",
        "test_word2index.update({\"<UNK>\":  0})\n",
        "for idx, v in enumerate(test_vocab):\n",
        "        test_word2index.update({v:  idx + 1})\n",
        "\n",
        "test_vocab.append('<UNK>')\n",
        "\n",
        "test_index2word = {v:k for k, v in test_word2index.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJ9fbW4HStss"
      },
      "source": [
        "**Function to get embedding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "BoPMJGJGSkZk"
      },
      "outputs": [],
      "source": [
        "def get_embed(word, current_model):\n",
        "    try:\n",
        "        index = word2index[word]\n",
        "    except :\n",
        "        index = word2index['<UNK>'] #unknown\n",
        "    word = torch.LongTensor([index])\n",
        "    \n",
        "    embed =  (current_model.embedding_v(word)+current_model.embedding_u(word))/2\n",
        "    return np.array(embed[0].detach().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "3W4MnIy1SwNP"
      },
      "outputs": [],
      "source": [
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def cos_sim(a, b):\n",
        "    cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
        "    return cos_sim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "bV3nt_VOS4hu"
      },
      "outputs": [],
      "source": [
        "def find_analogy(a,b,c, current_model,vocabs=vocab):\n",
        "    emb_a, emb_b, emb_c = get_embed(a, current_model), get_embed(b, current_model), get_embed(c, current_model)\n",
        "    vector = emb_b - emb_a + emb_c\n",
        "    similarity = -1 \n",
        "    \n",
        "    for vocab in vocabs:\n",
        "        if vocab not in [a,b,c]: #ignore input words itself\n",
        "            current_sim = cos_sim(vector,get_embed(vocab, current_model))\n",
        "            if current_sim > similarity:\n",
        "                similarity = current_sim #update better one\n",
        "                d = (vocab, similarity)\n",
        "    return d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKtNVMl0TGnl",
        "outputId": "56b285d3-c428-45fb-c0cb-58b33f23b282"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GloVe(\n",
              "  (embedding_v): Embedding(4273, 100)\n",
              "  (embedding_u): Embedding(4273, 100)\n",
              "  (v_bias): Embedding(4273, 1)\n",
              "  (u_bias): Embedding(4273, 1)\n",
              ")"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_model = GloVe(voc_size, embedding_size)\n",
        "current_model.load_state_dict(torch.load('/content/Glove_5000.pth'))\n",
        "current_model.eval()\n",
        "#find_analogy('man', 'woman', 'adult')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "Zb1Yk4xoT66O"
      },
      "outputs": [],
      "source": [
        "test_embed = get_embed('good', current_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3RVVl5GT_mr",
        "outputId": "971f2658-0f86-4542-98bc-eb17a1ba83e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-0.05750549, -0.16518529,  0.53817827, -0.0743229 ,  1.721066  ,\n",
              "       -0.10337168, -0.97622836, -0.1463296 ,  0.3981204 ,  0.19209267,\n",
              "       -0.4529785 , -1.1922284 , -0.60328484,  0.84476286,  0.08506405,\n",
              "        0.6684439 , -0.06805685, -0.548988  , -0.2610401 ,  1.2241261 ,\n",
              "       -0.12974629, -1.0905304 ,  0.38937962, -0.0477578 , -0.37867856,\n",
              "        0.24111071,  0.29999048,  0.64772016, -0.2629413 , -0.04437515,\n",
              "        0.85509324,  0.41944277,  0.0048731 , -0.75252914,  0.7442796 ,\n",
              "       -0.83230984,  1.4986928 , -0.72606933,  0.45738572,  0.87141746,\n",
              "       -1.6333348 , -0.57801944,  0.62597513, -0.16132307,  0.9539615 ,\n",
              "       -0.9647589 ,  0.37832868,  0.13204916, -0.38291058,  0.2807761 ,\n",
              "       -0.22834037, -0.29457176,  0.33706522, -0.40950483,  1.2025487 ,\n",
              "       -0.1164791 ,  1.4171383 , -0.9979413 ,  0.5807188 , -0.9665699 ,\n",
              "        0.7063676 , -0.24104436,  0.95203143,  0.16032602, -0.6191424 ,\n",
              "        0.6847868 ,  0.52519435,  0.57415366, -0.3356182 ,  0.8113811 ,\n",
              "        1.1514966 ,  0.25794345,  0.47199002, -0.6627539 , -0.5985563 ,\n",
              "        0.4560126 ,  0.95307195,  0.41291806,  1.6211972 ,  0.12516373,\n",
              "        0.3225025 , -1.5301716 ,  0.25015485, -0.36596316,  0.6470003 ,\n",
              "       -0.42373496,  0.43070942, -1.1690004 ,  1.046476  ,  0.7134719 ,\n",
              "        0.21508527, -0.07226959, -0.38140422, -1.5476835 , -0.04839686,\n",
              "        0.9295937 , -0.2969423 ,  0.8008231 , -0.18983072,  0.42294854],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_embed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9tDRgjyUMoj",
        "outputId": "9ae7f652-41b8-43bf-8f1f-4ea43f50d7e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('married', 0.3612438)"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "find_analogy('good', 'better', 'man',current_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPTdOXWwUgrQ"
      },
      "source": [
        "**Now Trying to do semantic Testing using Glove Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "r8Xx1Ai2WjVt"
      },
      "outputs": [],
      "source": [
        "def check_accruacy(y, yhat):\n",
        "    if y == yhat:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def test_accruacy_batch(data, current_model):\n",
        "    counter = 0\n",
        "    for sent in data:\n",
        "        label = sent[-1]\n",
        "        a, b, c = sent[:-1]\n",
        "        yhat = find_analogy(a, b, c,current_model)[0] # It's return in tuple form, so we need to slice to get word\n",
        "        if check_accruacy(label, yhat) == True:\n",
        "            counter = counter + 1\n",
        "    \n",
        "    return counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9YbInC2Viif",
        "outputId": "038dc6a2-a04a-4abb-90da-749dd224ac1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current_test = test_comparative\n",
            "0\n",
            "Current_test = test_nationality\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "current_model = GloVe(voc_size, embedding_size)\n",
        "current_model.load_state_dict(torch.load('/content/Glove_5000.pth'))\n",
        "current_model.eval()\n",
        "\n",
        "test_list = [test_comparative, test_nationality]\n",
        "test_list_name = ['test_comparative', 'test_nationality']\n",
        "\n",
        "for idx, current_test in enumerate(test_list):\n",
        "   sample_list = random.choices(current_test, k=100)\n",
        "   print(f'Current_test = {test_list_name[idx]}')\n",
        "   accruacy = test_accruacy_batch(sample_list, current_model)\n",
        "   print(accruacy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD0P3SrcXGVr"
      },
      "source": [
        "**Now Trying to do semantic using Skipgram Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "kwMki7UkYfSv"
      },
      "outputs": [],
      "source": [
        "def get_embed(word, current_model):\n",
        "    try:\n",
        "        index = word2index[word]\n",
        "    except :\n",
        "        index = word2index['<UNK>'] #unknown\n",
        "    word = torch.LongTensor([index])\n",
        "    \n",
        "    embed =  (current_model.embedding_center_word(word)+current_model.embedding_outside_word (word))/2\n",
        "    return np.array(embed[0].detach().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2NAfFDHW-5z",
        "outputId": "e2bc184c-5822-40ff-db87-7480f68fe865"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current_test = test_comparative\n",
            "0\n",
            "Current_test = test_nationality\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "embedding_size = 2\n",
        "current_model = Skipgram(voc_size, embedding_size)\n",
        "current_model.load_state_dict(torch.load('/content/Skipgrams_1000.pth'))\n",
        "current_model.eval()\n",
        "\n",
        "test_list = [test_comparative, test_nationality]\n",
        "test_list_name = ['test_comparative', 'test_nationality']\n",
        "\n",
        "for idx, current_test in enumerate(test_list):\n",
        "   sample_list = random.choices(current_test, k=100)\n",
        "   print(f'Current_test = {test_list_name[idx]}')\n",
        "   accruacy = test_accruacy_batch(sample_list, current_model)\n",
        "   print(accruacy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivXUPnHIZM_y"
      },
      "source": [
        "**semantic using CBOW Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgEIClvnY3UJ",
        "outputId": "e5e594a9-b29d-40ea-82b5-6f2f0dcd1412"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current_test = test_comparative\n",
            "0\n",
            "Current_test = test_nationality\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "embedding_size = 100\n",
        "current_model = Cbow(voc_size, embedding_size)\n",
        "current_model.load_state_dict(torch.load('/content/CBow_model_500.pth'))\n",
        "current_model.eval()\n",
        "\n",
        "test_list = [test_comparative, test_nationality]\n",
        "test_list_name = ['test_comparative', 'test_nationality']\n",
        "\n",
        "for idx, current_test in enumerate(test_list):\n",
        "   sample_list = random.choices(current_test, k=100)\n",
        "   print(f'Current_test = {test_list_name[idx]}')\n",
        "   accruacy = test_accruacy_batch(sample_list, current_model)\n",
        "   print(accruacy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMn6BPnWZp3w"
      },
      "source": [
        "**semantic  using Skipgram Negative Sampling Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NKvJidtY3aY",
        "outputId": "c72bd934-381c-4c22-be1b-c89ad1762ee9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current_test = test_comparative\n",
            "0\n",
            "Current_test = test_nationality\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "embedding_size = 100\n",
        "current_model = SkipgramNegSampling(voc_size, embedding_size)\n",
        "current_model.load_state_dict(torch.load('/content/Neg_Skipgrams_1000.pth'))\n",
        "current_model.eval()\n",
        "\n",
        "test_list = [test_comparative, test_nationality]\n",
        "test_list_name = ['test_comparative', 'test_nationality']\n",
        "\n",
        "for idx, current_test in enumerate(test_list):\n",
        "   sample_list = random.choices(current_test, k=100)\n",
        "   print(f'Current_test = {test_list_name[idx]}')\n",
        "   accruacy = test_accruacy_batch(sample_list, current_model)\n",
        "   print(accruacy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOWhOf1SarMq"
      },
      "source": [
        "**Now, Synthetic testing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "KexYo1Shbw2B",
        "outputId": "9a8f2e28-af0d-4aa4-9b5b-e2c1775f2005"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tiger</td>\n",
              "      <td>cat</td>\n",
              "      <td>7.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tiger</td>\n",
              "      <td>tiger</td>\n",
              "      <td>10.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>plane</td>\n",
              "      <td>car</td>\n",
              "      <td>5.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train</td>\n",
              "      <td>car</td>\n",
              "      <td>6.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>television</td>\n",
              "      <td>radio</td>\n",
              "      <td>6.77</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            0      1      2\n",
              "0       tiger    cat   7.35\n",
              "1       tiger  tiger  10.00\n",
              "2       plane    car   5.77\n",
              "3       train    car   6.31\n",
              "4  television  radio   6.77"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#trying to look syntatic dataset with python file\n",
        "# Import datasets\n",
        "import pandas as pd\n",
        "path = 'C:\\\\Users\\\\koira\\\\OneDrive\\\\Desktop\\\\ws353simrel (1).tar\\\\ws353simrel (1)\\\\wordsim353_sim_rel\\\\wordsim_similarity_goldstandard.txt'\n",
        "df = pd.read_table(path, header=None)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "W0NHg0Rbb5Wf",
        "outputId": "128e1ab7-43d0-487e-9c34-9d5d69c3f490"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tiger</td>\n",
              "      <td>cat</td>\n",
              "      <td>7.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tiger</td>\n",
              "      <td>tiger</td>\n",
              "      <td>10.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>plane</td>\n",
              "      <td>car</td>\n",
              "      <td>5.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train</td>\n",
              "      <td>car</td>\n",
              "      <td>6.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>television</td>\n",
              "      <td>radio</td>\n",
              "      <td>6.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>media</td>\n",
              "      <td>radio</td>\n",
              "      <td>7.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>bread</td>\n",
              "      <td>butter</td>\n",
              "      <td>6.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>cucumber</td>\n",
              "      <td>potato</td>\n",
              "      <td>5.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>doctor</td>\n",
              "      <td>nurse</td>\n",
              "      <td>7.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>professor</td>\n",
              "      <td>doctor</td>\n",
              "      <td>6.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>student</td>\n",
              "      <td>professor</td>\n",
              "      <td>6.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>smart</td>\n",
              "      <td>stupid</td>\n",
              "      <td>5.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>wood</td>\n",
              "      <td>forest</td>\n",
              "      <td>7.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>money</td>\n",
              "      <td>cash</td>\n",
              "      <td>9.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>king</td>\n",
              "      <td>queen</td>\n",
              "      <td>8.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>king</td>\n",
              "      <td>rook</td>\n",
              "      <td>5.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>bishop</td>\n",
              "      <td>rabbi</td>\n",
              "      <td>6.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>fuck</td>\n",
              "      <td>sex</td>\n",
              "      <td>9.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>football</td>\n",
              "      <td>soccer</td>\n",
              "      <td>9.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>football</td>\n",
              "      <td>basketball</td>\n",
              "      <td>6.81</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             0           1      2\n",
              "0        tiger         cat   7.35\n",
              "1        tiger       tiger  10.00\n",
              "2        plane         car   5.77\n",
              "3        train         car   6.31\n",
              "4   television       radio   6.77\n",
              "5        media       radio   7.42\n",
              "6        bread      butter   6.19\n",
              "7     cucumber      potato   5.92\n",
              "8       doctor       nurse   7.00\n",
              "9    professor      doctor   6.62\n",
              "10     student   professor   6.81\n",
              "11       smart      stupid   5.81\n",
              "12        wood      forest   7.73\n",
              "13       money        cash   9.15\n",
              "14        king       queen   8.58\n",
              "15        king        rook   5.92\n",
              "16      bishop       rabbi   6.69\n",
              "17        fuck         sex   9.44\n",
              "18    football      soccer   9.03\n",
              "19    football  basketball   6.81"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "synthetic_test_set = df.iloc[:20]\n",
        "synthetic_test_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RNnyPlj3cAVZ"
      },
      "outputs": [],
      "source": [
        "input_x1 = synthetic_test_set[0]\n",
        "input_x2 = synthetic_test_set[1]\n",
        "label = synthetic_test_set[2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "LlRPVT-QcMPs"
      },
      "outputs": [],
      "source": [
        "def get_embed(word, current_model):\n",
        "    try:\n",
        "        index = word2index[word]\n",
        "    except :\n",
        "        index = word2index['<UNK>'] #unknown\n",
        "    word = torch.LongTensor([index])\n",
        "    \n",
        "    embed =  (current_model.embedding_v(word)+current_model.embedding_u(word))/2\n",
        "    return np.array(embed[0].detach().numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82yXWUEIgsvh"
      },
      "source": [
        "**syntactic Testing on Glove method** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "BQrTE0bBc3L7"
      },
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "embedding_size=100\n",
        "current_model = GloVe(voc_size, embedding_size)\n",
        "current_model.load_state_dict(torch.load('/content/Glove_5000.pth'))\n",
        "current_model.eval()\n",
        "\n",
        "test_list = [test_comparative, test_nationality]\n",
        "test_list_name = ['test_comparative', 'test_nationality']\n",
        "\n",
        "results = []\n",
        "for idx in range(20): # We test with only fix 10 samples\n",
        "    emb_x1 = get_embed(input_x1[idx], current_model)\n",
        "    emb_x2 = get_embed(input_x2[idx], current_model)\n",
        "    yhat = stats.spearmanr(emb_x1, emb_x2)\n",
        "    yhat = yhat[0]\n",
        "    #print(yhat)\n",
        "    results.append(yhat)\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdTKMZC-dVDw",
        "outputId": "b2709a83-101d-4aaf-ad47-676603201013"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9999999999999999, 0.9999999999999999, 0.13777377737773777, 0.13777377737773777, -0.1195319531953195, -0.10435043504350434, 0.9999999999999999, 0.9999999999999999, -0.06871887188718871, -0.018577857785778577, -0.13172517251725172, 0.9999999999999999, 0.06568256825682568, -0.050561056105610555, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, -0.04604860486048604, 0.20056405640564054]\n"
          ]
        }
      ],
      "source": [
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek-OnnTpd9ZL",
        "outputId": "ded5e402-be26-4c5a-8d90-ba1e90136406"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "106.15907280549474\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "yhat = [i * 20 for i in results]\n",
        "mse = mse(label, yhat)\n",
        "print(mse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubYqJc_Tiuyv"
      },
      "source": [
        "**syntactic Testing on SkipGram method** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "k_LB8ktzddr-"
      },
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "\n",
        "def get_embed(word, current_model):\n",
        "    try:\n",
        "        index = word2index[word]\n",
        "    except :\n",
        "        index = word2index['<UNK>'] #unknown\n",
        "    word = torch.LongTensor([index])\n",
        "    \n",
        "    embed =  (current_model.embedding_center_word(word)+current_model.embedding_outside_word (word))/2\n",
        "    return np.array(embed[0].detach().numpy())\n",
        "\n",
        "embedding_size = 2\n",
        "current_model = Skipgram(voc_size, embedding_size)\n",
        "current_model.load_state_dict(torch.load('/content/Skipgrams_1000.pth'))\n",
        "current_model.eval()\n",
        "\n",
        "test_list = [test_comparative, test_nationality]\n",
        "test_list_name = ['test_comparative', 'test_nationality']\n",
        "\n",
        "results = []\n",
        "for idx in range(20): # We test with only fix 10 samples\n",
        "    emb_x1 = get_embed(input_x1[idx], current_model)\n",
        "    emb_x2 = get_embed(input_x2[idx], current_model)\n",
        "    yhat = stats.spearmanr(emb_x1, emb_x2)\n",
        "    yhat = yhat[0]\n",
        "    #print(yhat)\n",
        "    results.append(yhat)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaUfTwIvcVlY",
        "outputId": "72489192-db39-42b1-9f70-c92b35b58a6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, -0.9999999999999999, 0.9999999999999999]\n"
          ]
        }
      ],
      "source": [
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7gX_uGhhgND",
        "outputId": "3d65596a-23a7-426a-eab9-c58eac631e94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "199.89323999999988\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "yhat = [i * 20 for i in results]\n",
        "mse = mse(label, yhat)\n",
        "print(mse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iwzAIU1i8hh"
      },
      "source": [
        "**syntactic Testing on CBOW method** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "1nIGEPayerTF"
      },
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "\n",
        "def get_embed(word, current_model):\n",
        "    try:\n",
        "        index = word2index[word]\n",
        "    except :\n",
        "        index = word2index['<UNK>'] #unknown\n",
        "    word = torch.LongTensor([index])\n",
        "    \n",
        "    embed =  (current_model.embedding_center_word(word)+current_model.embedding_outside_word (word))/2\n",
        "    return np.array(embed[0].detach().numpy())\n",
        "\n",
        "embedding_size = 100\n",
        "current_model = Cbow(voc_size, embedding_size)\n",
        "current_model.load_state_dict(torch.load('/content/CBow_model_500.pth'))\n",
        "current_model.eval()\n",
        "\n",
        "test_list = [test_comparative, test_nationality]\n",
        "test_list_name = ['test_comparative', 'test_nationality']\n",
        "\n",
        "results = []\n",
        "for idx in range(20): # We test with only fix 10 samples\n",
        "    emb_x1 = get_embed(input_x1[idx], current_model)\n",
        "    emb_x2 = get_embed(input_x2[idx], current_model)\n",
        "    yhat = stats.spearmanr(emb_x1, emb_x2)\n",
        "    yhat = yhat[0]\n",
        "    #print(yhat)\n",
        "    results.append(yhat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fb81acuBe5oV",
        "outputId": "0e076dca-392b-4ca0-a039-a768b0f2e5ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9999999999999999, 0.9999999999999999, -0.017701770177017698, -0.017701770177017698, 0.13186918691869187, -0.0207020702070207, 0.9999999999999999, 0.9999999999999999, 0.06977497749774977, 0.06483048304830481, 0.1585238523852385, 0.9999999999999999, -0.05359735973597359, -0.007176717671767176, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.12124812481248125, 0.09236123612361234]\n"
          ]
        }
      ],
      "source": [
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSPhEiNIhbg1",
        "outputId": "6a83c718-1978-4e53-a694-c5b219a6fdbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "96.6566125382979\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "yhat = [i * 20 for i in results]\n",
        "mse = mse(label, yhat)\n",
        "print(mse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtkTdbWXjkbJ"
      },
      "source": [
        "**syntactic Testing on SkipGram Negative Sampling  method** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "DNrWUnECe9iQ"
      },
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "\n",
        "def get_embed(word, current_model):\n",
        "    try:\n",
        "        index = word2index[word]\n",
        "    except :\n",
        "        index = word2index['<UNK>'] #unknown\n",
        "    word = torch.LongTensor([index])\n",
        "    \n",
        "    embed =  (current_model.embedding_center_word(word)+current_model.embedding_outside_word (word))/2\n",
        "    return np.array(embed[0].detach().numpy())\n",
        "\n",
        "embedding_size = 100\n",
        "current_model = SkipgramNegSampling(voc_size, embedding_size)\n",
        "current_model.load_state_dict(torch.load('/content/Neg_Skipgrams_1000.pth'))\n",
        "current_model.eval()\n",
        "\n",
        "test_list = [test_comparative, test_nationality]\n",
        "test_list_name = ['test_comparative', 'test_nationality']\n",
        "\n",
        "results = []\n",
        "for idx in range(20): # We test with only fix 10 samples\n",
        "    emb_x1 = get_embed(input_x1[idx], current_model)\n",
        "    emb_x2 = get_embed(input_x2[idx], current_model)\n",
        "    yhat = stats.spearmanr(emb_x1, emb_x2)\n",
        "    yhat = yhat[0]\n",
        "    #print(yhat)\n",
        "    results.append(yhat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3nJay5vfOLA",
        "outputId": "9d220588-9bcb-4f45-9682-fd6d955d7929"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9999999999999999, 0.9999999999999999, 0.1318211821182118, 0.1318211821182118, -0.02181818181818182, 0.22720672067206718, 0.9999999999999999, 0.9999999999999999, 0.1029222922292229, 0.14184218421842185, 0.08710471047104709, 0.9999999999999999, 0.014665466546654665, -0.009876987698769876, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.00021602160216021597, 0.10432643264326431]\n"
          ]
        }
      ],
      "source": [
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8Ln6btJg6IT",
        "outputId": "9326db6d-5e69-4e57-ffc0-34a4717cc8c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "93.10300914238675\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "yhat = [i * 20 for i in results]\n",
        "mse = mse(label, yhat)\n",
        "print(mse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ELoqFOzfUyU"
      },
      "source": [
        "**Testing with pretrained model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ajjM5YRofQSf"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "from gensim.test.utils import datapath\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "\n",
        "#you have to put this file in some python/gensim directory; just run it and it will inform where to put....\n",
        "# Download from https://github.com/stanfordnlp/GloVe\n",
        "glove_file = datapath('C:\\\\Users\\\\koira\\\\OneDrive\\\\Desktop\\\\ws353simrel (1).tar\\\\glove.6B\\\\glove.6B.100d.txt')\n",
        "model = KeyedVectors.load_word2vec_format(glove_file, binary=False, no_header=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Lkzw_GurfjVO"
      },
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "yhat = list()\n",
        "for i in range(20):\n",
        "    emb_x1 = model[input_x1[i]]\n",
        "    emb_x2 = model[input_x2[i]]\n",
        "    result = stats.spearmanr(emb_x1, emb_x2)\n",
        "    result = result[0]\n",
        "    yhat.append(result)\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "bFbihym1jcIT"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "yhat = [i * 20 for i in yhat]\n",
        "mse_error = mse(label, yhat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "37.76402492008951\n"
          ]
        }
      ],
      "source": [
        "print(mse_error)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ENZXGksQh1qE"
      },
      "source": [
        "**Conlusion:**\n",
        "\n",
        "Since, I train glove model upto 5000 epoch, skipgram with 1000 epoch, CBOW with 500 epoch, skipgram with negative sampling with 1000 epoch but, on semantic similarity i didn't got any result. All the result i got is 0. \n",
        "\n",
        "But, on syntactic Testing on Glove, SkipGram, CBoW, Negative Sampling tested on 20 dataset following are MSE error : 106.15, 199.89, 96.65 and 93.10.\n",
        "\n",
        "While Training on Pretrained model downloaded (glove.6B.100d.txt) the MSE error is 37.76"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "bb0cb95bfde73c68cb05ded0c6f48850cf566e0c9ce35e8d90131e8707a36ff6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
